{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_header"
   },
   "source": [
    "# 🧮 Magpie: 6ドメイン数学データセット生成 (Colab軽量版)\n",
    "\n",
    "**Google Colab T4最適化版**: vLLMの代わりにTransformersライブラリを使用した確実動作版\n",
    "\n",
    "## 🎯 特徴\n",
    "- ✅ **T4 GPU対応**: 確実にGoogle Colabで動作\n",
    "- ✅ **軽量モデル**: Qwen2.5-3B-Instructで高品質生成\n",
    "- ✅ **ドメイン特化**: 6つの数学領域別問題生成\n",
    "- ✅ **自動統合**: データマージ・シャッフル機能\n",
    "- ✅ **高速インストール**: 依存関係最小化\n",
    "\n",
    "## 📊 対応ドメイン\n",
    "1. **Algebra** (代数学): 方程式、多項式、関数\n",
    "2. **Applied Mathematics** (応用数学): 微分方程式、最適化\n",
    "3. **Calculus** (微積分学): 微積分、極限、級数\n",
    "4. **Discrete Mathematics** (離散数学): 組合せ、グラフ理論\n",
    "5. **Geometry** (幾何学): 解析幾何、空間図形\n",
    "6. **Number Theory** (数論): 素数、合同式、暗号応用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "settings_header"
   },
   "source": [
    "## ⚙️ ユーザー設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "user_settings"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ユーザー設定 (T4 GPU最適化)\n",
    "# =============================================================================\n",
    "\n",
    "# 基本設定\n",
    "PROBLEMS_PER_DOMAIN = 15      # 各ドメインの問題数 (T4向け軽量設定)\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"  # T4で確実動作\n",
    "USE_4BIT_QUANTIZATION = True  # メモリ使用量削減\n",
    "\n",
    "# 生成パラメータ\n",
    "INSTRUCTION_TEMP = 1.2\n",
    "INSTRUCTION_TOP_P = 0.9\n",
    "RESPONSE_TEMP = 0.3\n",
    "RESPONSE_TOP_P = 0.9\n",
    "MAX_NEW_TOKENS = 1024\n",
    "\n",
    "# 出力設定\n",
    "OUTPUT_DIR = \"/content/magpie_6domains_lightweight\"\n",
    "DATASET_NAME = f\"HLE_6Domains_Math_{PROBLEMS_PER_DOMAIN * 6}\"\n",
    "\n",
    "print(f\"🚀 軽量設定完了\")\n",
    "print(f\"📊 モデル: {MODEL_NAME}\")\n",
    "print(f\"📈 問題数: {PROBLEMS_PER_DOMAIN} × 6ドメイン = {PROBLEMS_PER_DOMAIN * 6}問題\")\n",
    "print(f\"🔧 4bit量子化: {'有効' if USE_4BIT_QUANTIZATION else '無効'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_header"
   },
   "source": [
    "## 🔧 環境セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 軽量依存関係インストール\n",
    "# =============================================================================\n",
    "\n",
    "!pip install -q transformers>=4.40.0\n",
    "!pip install -q torch>=2.0.0\n",
    "!pip install -q accelerate\n",
    "!pip install -q bitsandbytes  # 4bit量子化用\n",
    "!pip install -q datasets\n",
    "!pip install -q tqdm\n",
    "!pip install -q matplotlib seaborn pandas numpy\n",
    "\n",
    "print(\"✅ パッケージインストール完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu_check"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GPU環境確認\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    \n",
    "    print(f\"🎮 GPU情報:\")\n",
    "    print(f\"   名前: {gpu_name}\")\n",
    "    print(f\"   メモリ: {gpu_memory:.1f}GB\")\n",
    "    \n",
    "    if gpu_memory < 20:  # T4相当\n",
    "        print(f\"📱 T4 GPU検出 - 軽量設定で最適化\")\n",
    "        if PROBLEMS_PER_DOMAIN > 20:\n",
    "            PROBLEMS_PER_DOMAIN = 15\n",
    "            print(f\"📉 問題数を{PROBLEMS_PER_DOMAIN}に調整\")\n",
    "else:\n",
    "    print(\"❌ GPU が利用できません\")\n",
    "    raise RuntimeError(\"GPU必須です\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"📁 作業ディレクトリ: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "core_functions_header"
   },
   "source": [
    "## 🔧 コア機能実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "domain_templates"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ドメイン特化システムプロンプト\n",
    "# =============================================================================\n",
    "\n",
    "DOMAIN_TEMPLATES = {\n",
    "    \"algebra\": {\n",
    "        \"name\": \"代数学 (Algebra)\",\n",
    "        \"system_prompt\": \"\"\"あなたは代数学専門の数学教師です。以下の領域に特化した高品質な数学問題を生成してください：\n",
    "\n",
    "**対象領域：**\n",
    "- 線形代数：行列、ベクトル空間、固有値・固有ベクトル\n",
    "- 抽象代数：群、環、体の理論\n",
    "- 多項式代数：因数分解、根と係数の関係\n",
    "- 方程式論：連立方程式、高次方程式\n",
    "- 線形変換：基底変換、対角化\n",
    "\n",
    "**問題の特徴：**\n",
    "- 概念の深い理解を問う問題\n",
    "- 証明や論理的推論を含む\n",
    "- 実際の応用例との関連\n",
    "- 段階的解法が明確な問題\n",
    "\n",
    "高等レベル試験に適した代数学の問題を1つ生成してください。問題は明確で完結な文章で記述してください。\"\"\"\n",
    "    },\n",
    "    \"applied-mathematics\": {\n",
    "        \"name\": \"応用数学 (Applied Mathematics)\", \n",
    "        \"system_prompt\": \"\"\"あなたは応用数学専門の研究者です。以下の領域に特化した実践的な数学問題を生成してください：\n",
    "\n",
    "**対象領域：**\n",
    "- 微分方程式：常微分方程式、偏微分方程式\n",
    "- 最適化理論：線形計画法、非線形最適化\n",
    "- 数値解析：数値積分、数値微分、近似解法\n",
    "- 確率・統計：統計的推測、回帰分析\n",
    "- 動的システム：カオス理論、フラクタル\n",
    "\n",
    "**問題の特徴：**\n",
    "- 現実世界の問題をモデル化\n",
    "- 工学・物理・経済学との関連\n",
    "- 数値計算やシミュレーション要素\n",
    "- アルゴリズム的思考を要求\n",
    "\n",
    "高等レベル試験に適した応用数学の問題を1つ生成してください。問題は明確で完結な文章で記述してください。\"\"\"\n",
    "    },\n",
    "    \"calculus\": {\n",
    "        \"name\": \"微積分学 (Calculus)\",\n",
    "        \"system_prompt\": \"\"\"あなたは微積分学専門の数学教授です。以下の領域に特化した理論的・実践的な問題を生成してください：\n",
    "\n",
    "**対象領域：**\n",
    "- 極限理論：関数の極限、連続性\n",
    "- 微分法：導関数、偏微分、全微分\n",
    "- 積分法：不定積分、定積分、重積分\n",
    "- 級数理論：テイラー級数、フーリエ級数\n",
    "- ベクトル解析：勾配、発散、回転\n",
    "\n",
    "**問題の特徴：**\n",
    "- 厳密な数学的証明を含む\n",
    "- 幾何学的直観との結合\n",
    "- 物理現象との関連\n",
    "- 計算技法の習得を促進\n",
    "\n",
    "高等レベル試験に適した微積分学の問題を1つ生成してください。問題は明確で完結な文章で記述してください。\"\"\"\n",
    "    },\n",
    "    \"discrete-mathematics\": {\n",
    "        \"name\": \"離散数学 (Discrete Mathematics)\",\n",
    "        \"system_prompt\": \"\"\"あなたは離散数学とコンピュータサイエンス専門の教員です。以下の領域に特化した論理的思考を鍛える問題を生成してください：\n",
    "\n",
    "**対象領域：**\n",
    "- 組合せ論：順列、組合せ、鳩の巣原理\n",
    "- グラフ理論：グラフの性質、最短経路、ネットワーク\n",
    "- 論理学：命題論理、述語論理、推論規則\n",
    "- 集合論：集合演算、関係、写像\n",
    "- 計算複雑性：アルゴリズム、計算量理論\n",
    "\n",
    "**問題の特徴：**\n",
    "- アルゴリズム的思考を重視\n",
    "- コンピュータサイエンスへの応用\n",
    "- 構成的証明手法\n",
    "- パズル的要素を含む創意工夫\n",
    "\n",
    "高等レベル試験に適した離散数学の問題を1つ生成してください。問題は明確で完結な文章で記述してください。\"\"\"\n",
    "    },\n",
    "    \"geometry\": {\n",
    "        \"name\": \"幾何学 (Geometry)\",\n",
    "        \"system_prompt\": \"\"\"あなたは幾何学専門の数学教師です。以下の領域に特化した視覚的理解を促進する問題を生成してください：\n",
    "\n",
    "**対象領域：**\n",
    "- 解析幾何：座標系、直線・円・楕円の方程式\n",
    "- 立体幾何：空間図形、体積・表面積の計算\n",
    "- 射影幾何：射影変換、無限遠点\n",
    "- 微分幾何：曲線・曲面の理論\n",
    "- トポロジー：位相的性質、連続変形\n",
    "\n",
    "**問題の特徴：**\n",
    "- 図形の性質や関係性に焦点\n",
    "- 視覚的イメージと代数的計算の結合\n",
    "- 空間認識能力の向上\n",
    "- 美的側面も重視した問題設計\n",
    "\n",
    "高等レベル試験に適した幾何学の問題を1つ生成してください。問題は明確で完結な文章で記述してください。\"\"\"\n",
    "    },\n",
    "    \"number-theory\": {\n",
    "        \"name\": \"数論 (Number Theory)\",\n",
    "        \"system_prompt\": \"\"\"あなたは数論専門の数学研究者です。以下の領域に特化した純粋数学の美しさを伝える問題を生成してください：\n",
    "\n",
    "**対象領域：**\n",
    "- 初等数論：素数、最大公約数、ユークリッドの互除法\n",
    "- 合同式理論：モジュラー算術、中国剰余定理\n",
    "- 二次形式：ペル方程式、連分数\n",
    "- 解析的数論：素数定理、ゼータ関数\n",
    "- 暗号理論：RSA暗号、楕円曲線暗号\n",
    "\n",
    "**問題の特徴：**\n",
    "- 数の本質的性質を探究\n",
    "- 歴史的背景や数学者のエピソード\n",
    "- 現代暗号学への応用\n",
    "- 厳密な証明技法の習得\n",
    "\n",
    "高等レベル試験に適した数論の問題を1つ生成してください。問題は明確で完結な文章で記述してください。\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "DOMAINS = list(DOMAIN_TEMPLATES.keys())\n",
    "\n",
    "print(\"🎯 ドメイン特化システム準備完了\")\n",
    "for domain, info in DOMAIN_TEMPLATES.items():\n",
    "    print(f\"   📚 {info['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "transformers_engine"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Transformers軽量生成エンジン\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "class LightweightMagpieGenerator:\n",
    "    def __init__(self, model_name, use_4bit=True):\n",
    "        self.model_name = model_name\n",
    "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        print(f\"🚀 モデル初期化中: {model_name}\")\n",
    "        \n",
    "        # 4bit量子化設定\n",
    "        if use_4bit:\n",
    "            bnb_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_use_double_quant=True,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_compute_dtype=torch.bfloat16\n",
    "            )\n",
    "            print(\"🔧 4bit量子化有効\")\n",
    "        else:\n",
    "            bnb_config = None\n",
    "        \n",
    "        try:\n",
    "            # トークナイザー\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            if self.tokenizer.pad_token is None:\n",
    "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            \n",
    "            # モデル\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                quantization_config=bnb_config,\n",
    "                device_map=\"auto\",\n",
    "                torch_dtype=torch.bfloat16 if not use_4bit else None,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            \n",
    "            print(\"✅ モデル初期化成功\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ モデル初期化エラー: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_text(self, prompt, max_tokens=512, temperature=1.0, top_p=0.9):\n",
    "        \"\"\"テキスト生成\"\"\"\n",
    "        # ChatML形式でフォーマット\n",
    "        formatted_prompt = f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "        \n",
    "        # エンコード\n",
    "        inputs = self.tokenizer(\n",
    "            formatted_prompt, \n",
    "            return_tensors=\"pt\", \n",
    "            truncation=True, \n",
    "            max_length=2048\n",
    "        ).to(self.model.device)\n",
    "        \n",
    "        # 生成\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.pad_token_id,\n",
    "                eos_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # デコード\n",
    "        generated = self.tokenizer.decode(\n",
    "            outputs[0][inputs['input_ids'].shape[1]:], \n",
    "            skip_special_tokens=True\n",
    "        ).strip()\n",
    "        \n",
    "        return generated\n",
    "    \n",
    "    def generate_instructions(self, domain, num_problems, output_file):\n",
    "        \"\"\"ドメイン特化問題生成\"\"\"\n",
    "        domain_info = DOMAIN_TEMPLATES[domain]\n",
    "        print(f\"\\n📝 {domain_info['name']} 問題生成開始 ({num_problems}問)\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i in tqdm(range(num_problems), desc=f\"{domain} 問題生成\"):\n",
    "            try:\n",
    "                # 問題生成\n",
    "                instruction = self.generate_text(\n",
    "                    domain_info['system_prompt'],\n",
    "                    max_tokens=512,\n",
    "                    temperature=INSTRUCTION_TEMP,\n",
    "                    top_p=INSTRUCTION_TOP_P\n",
    "                )\n",
    "                \n",
    "                if instruction and len(instruction.strip()) > 20:\n",
    "                    results.append({\n",
    "                        \"id\": i,\n",
    "                        \"instruction\": instruction.strip(),\n",
    "                        \"domain\": domain,\n",
    "                        \"created\": self.timestamp,\n",
    "                        \"gen_input_configs\": {\n",
    "                            \"model\": self.model_name,\n",
    "                            \"temperature\": INSTRUCTION_TEMP,\n",
    "                            \"top_p\": INSTRUCTION_TOP_P,\n",
    "                            \"domain\": domain\n",
    "                        }\n",
    "                    })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 問題{i}生成エラー: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # ファイル保存\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"✅ {domain_info['name']} 問題生成完了: {len(results)}問\")\n",
    "        return results\n",
    "    \n",
    "    def generate_responses(self, instructions_file, output_file):\n",
    "        \"\"\"Chain-of-Thought解答生成\"\"\"\n",
    "        print(f\"\\n🧠 解答生成開始: {instructions_file}\")\n",
    "        \n",
    "        # 問題読み込み\n",
    "        with open(instructions_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        for i, item in enumerate(tqdm(data, desc=\"解答生成\")):\n",
    "            try:\n",
    "                domain_info = DOMAIN_TEMPLATES[item['domain']]\n",
    "                prompt = f\"\"\"以下の{domain_info['name']}の問題に、段階的思考プロセス（Chain-of-Thought）を用いて詳細に解答してください。\n",
    "\n",
    "問題: {item['instruction']}\n",
    "\n",
    "解答:\"\"\"\n",
    "                \n",
    "                response = self.generate_text(\n",
    "                    prompt,\n",
    "                    max_tokens=MAX_NEW_TOKENS,\n",
    "                    temperature=RESPONSE_TEMP,\n",
    "                    top_p=RESPONSE_TOP_P\n",
    "                )\n",
    "                \n",
    "                item['response'] = response.strip()\n",
    "                item['gen_response_configs'] = {\n",
    "                    \"model\": self.model_name,\n",
    "                    \"temperature\": RESPONSE_TEMP,\n",
    "                    \"top_p\": RESPONSE_TOP_P\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 解答{i}生成エラー: {e}\")\n",
    "                item['response'] = \"解答生成エラー\"\n",
    "                continue\n",
    "        \n",
    "        # ファイル保存\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"✅ 解答生成完了: {len(data)}問\")\n",
    "        return data\n",
    "\n",
    "print(\"🔧 軽量生成エンジン準備完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_integration"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# データ統合・シャッフル機能\n",
    "# =============================================================================\n",
    "\n",
    "import glob\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def merge_domain_datasets(data_dir, output_file, sharegpt_file=None):\n",
    "    \"\"\"6ドメインデータセットの統合・シャッフル\"\"\"\n",
    "    print(\"\\n🔄 ドメインデータセット統合開始\")\n",
    "    \n",
    "    all_data = []\n",
    "    domain_counts = {}\n",
    "    \n",
    "    # 各ドメインのデータ読み込み\n",
    "    for domain in DOMAINS:\n",
    "        pattern = f\"{data_dir}/*{domain}*ins_res.json\"\n",
    "        files = glob.glob(pattern)\n",
    "        \n",
    "        if files:\n",
    "            latest_file = max(files, key=lambda x: os.path.getctime(x))\n",
    "            print(f\"📂 {domain}: {latest_file}\")\n",
    "            \n",
    "            with open(latest_file, 'r', encoding='utf-8') as f:\n",
    "                domain_data = json.load(f)\n",
    "            \n",
    "            # メタデータ追加\n",
    "            for item in domain_data:\n",
    "                item['source'] = 'magpie-lightweight'\n",
    "                item['dataset_version'] = '1.0'\n",
    "                if 'domain' not in item:\n",
    "                    item['domain'] = domain\n",
    "            \n",
    "            all_data.extend(domain_data)\n",
    "            domain_counts[domain] = len(domain_data)\n",
    "            print(f\"✅ {domain}: {len(domain_data)}問題\")\n",
    "        else:\n",
    "            print(f\"⚠️ {domain}: データファイル未発見\")\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"❌ 統合可能なデータがありません\")\n",
    "        return None\n",
    "    \n",
    "    # シャッフル\n",
    "    random.shuffle(all_data)\n",
    "    \n",
    "    # ID再割り当て\n",
    "    for i, item in enumerate(all_data):\n",
    "        item['id'] = i\n",
    "    \n",
    "    # 統合ファイル保存\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # ShareGPT形式変換\n",
    "    if sharegpt_file:\n",
    "        convert_to_sharegpt(all_data, sharegpt_file)\n",
    "    \n",
    "    # 統計表示\n",
    "    print(f\"\\n📊 統合結果:\")\n",
    "    print(f\"   総問題数: {len(all_data)}\")\n",
    "    print(f\"   ドメイン分布:\")\n",
    "    for domain, count in domain_counts.items():\n",
    "        print(f\"     {DOMAIN_TEMPLATES[domain]['name']}: {count}問題\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def convert_to_sharegpt(data, output_file):\n",
    "    \"\"\"ShareGPT形式変換\"\"\"\n",
    "    print(f\"🔄 ShareGPT形式変換: {output_file}\")\n",
    "    \n",
    "    sharegpt_data = []\n",
    "    for item in data:\n",
    "        sharegpt_item = {\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": item['instruction']\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": item['response']\n",
    "                }\n",
    "            ],\n",
    "            \"domain\": item['domain'],\n",
    "            \"source\": item.get('source', 'magpie-lightweight'),\n",
    "            \"id\": item['id']\n",
    "        }\n",
    "        sharegpt_data.append(sharegpt_item)\n",
    "    \n",
    "    # JSONL形式で保存\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for item in sharegpt_data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"✅ ShareGPT変換完了: {len(sharegpt_data)}項目\")\n",
    "\n",
    "print(\"🔧 データ統合機能準備完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generation_header"
   },
   "source": [
    "## 🚀 6ドメインデータ生成実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "main_generation"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# メイン実行: 6ドメインデータ生成・統合\n",
    "# =============================================================================\n",
    "\n",
    "import traceback\n",
    "\n",
    "def main_generation_pipeline():\n",
    "    \"\"\"メイン生成パイプライン\"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n🚀 6ドメインデータ生成開始 (軽量版)\")\n",
    "    print(f\"📊 設定: {MODEL_NAME}, 各{PROBLEMS_PER_DOMAIN}問題\")\n",
    "    print(f\"⏰ 開始時刻: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    try:\n",
    "        # 生成エンジン初期化\n",
    "        generator = LightweightMagpieGenerator(\n",
    "            model_name=MODEL_NAME,\n",
    "            use_4bit=USE_4BIT_QUANTIZATION\n",
    "        )\n",
    "        \n",
    "        generated_files = []\n",
    "        \n",
    "        # 各ドメインの生成\n",
    "        for i, domain in enumerate(DOMAINS, 1):\n",
    "            domain_info = DOMAIN_TEMPLATES[domain]\n",
    "            print(f\"\\n📚 [{i}/{len(DOMAINS)}] {domain_info['name']} 処理中...\")\n",
    "            \n",
    "            try:\n",
    "                # ファイル名生成\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                ins_file = f\"{OUTPUT_DIR}/{domain}_{PROBLEMS_PER_DOMAIN}_{timestamp}_ins.json\"\n",
    "                res_file = f\"{OUTPUT_DIR}/{domain}_{PROBLEMS_PER_DOMAIN}_{timestamp}_ins_res.json\"\n",
    "                \n",
    "                # 問題生成\n",
    "                instructions = generator.generate_instructions(domain, PROBLEMS_PER_DOMAIN, ins_file)\n",
    "                \n",
    "                # 解答生成\n",
    "                responses = generator.generate_responses(ins_file, res_file)\n",
    "                \n",
    "                generated_files.append(res_file)\n",
    "                print(f\"✅ {domain_info['name']} 完了\")\n",
    "                \n",
    "                # メモリクリア\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ {domain_info['name']} エラー: {e}\")\n",
    "                print(traceback.format_exc())\n",
    "                continue\n",
    "        \n",
    "        # データ統合\n",
    "        if generated_files:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            merged_file = f\"{OUTPUT_DIR}/{DATASET_NAME}_{timestamp}.json\"\n",
    "            sharegpt_file = f\"{OUTPUT_DIR}/{DATASET_NAME}_{timestamp}_sharegpt.jsonl\"\n",
    "            \n",
    "            print(f\"\\n🔄 データ統合開始...\")\n",
    "            merged_data = merge_domain_datasets(OUTPUT_DIR, merged_file, sharegpt_file)\n",
    "            \n",
    "            if merged_data:\n",
    "                print(f\"\\n🎉 全処理完了!\")\n",
    "                print(f\"📁 統合ファイル: {merged_file}\")\n",
    "                print(f\"📁 ShareGPT: {sharegpt_file}\")\n",
    "                \n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"⏱️ 実行時間: {elapsed/60:.1f}分\")\n",
    "                \n",
    "                return merged_file, sharegpt_file\n",
    "            else:\n",
    "                print(\"❌ データ統合に失敗\")\n",
    "        else:\n",
    "            print(\"❌ 生成されたファイルがありません\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 重大エラー: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        return None, None\n",
    "\n",
    "# 実行\n",
    "merged_file, sharegpt_file = main_generation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_download"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# データダウンロード\n",
    "# =============================================================================\n",
    "\n",
    "import zipfile\n",
    "from google.colab import files\n",
    "\n",
    "def download_generated_data():\n",
    "    \"\"\"生成データダウンロード\"\"\"\n",
    "    print(\"\\n📦 ダウンロード準備中...\")\n",
    "    \n",
    "    # 利用可能ファイル検索\n",
    "    available_files = []\n",
    "    \n",
    "    # 統合データファイル\n",
    "    json_files = glob.glob(f\"{OUTPUT_DIR}/*{DATASET_NAME}*.json\")\n",
    "    jsonl_files = glob.glob(f\"{OUTPUT_DIR}/*{DATASET_NAME}*.jsonl\")\n",
    "    \n",
    "    available_files.extend(json_files)\n",
    "    available_files.extend(jsonl_files)\n",
    "    \n",
    "    if not available_files:\n",
    "        print(\"❌ ダウンロード可能なファイルがありません\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📋 ダウンロード対象ファイル:\")\n",
    "    for file_path in available_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        size = os.path.getsize(file_path) / 1024  # KB\n",
    "        print(f\"   📄 {filename} ({size:.1f}KB)\")\n",
    "    \n",
    "    # 個別ダウンロード\n",
    "    for file_path in available_files:\n",
    "        try:\n",
    "            print(f\"⬇️ ダウンロード中: {os.path.basename(file_path)}\")\n",
    "            files.download(file_path)\n",
    "            print(f\"✅ 完了\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ エラー: {e}\")\n",
    "    \n",
    "    print(\"\\n🎉 ダウンロード完了!\")\n",
    "\n",
    "# ダウンロード実行\n",
    "if merged_file:\n",
    "    download_generated_data()\n",
    "else:\n",
    "    print(\"⚠️ ダウンロード対象データがありません\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "execution_summary"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 実行結果サマリー\n",
    "# =============================================================================\n",
    "\n",
    "def print_execution_summary():\n",
    "    \"\"\"実行結果サマリー表示\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎉 Magpie 6ドメイン数学データセット生成完了 (軽量版)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\n📊 生成設定:\")\n",
    "    print(f\"   🤖 モデル: {MODEL_NAME}\")\n",
    "    print(f\"   📝 各ドメイン問題数: {PROBLEMS_PER_DOMAIN}\")\n",
    "    print(f\"   🎯 総問題数: {PROBLEMS_PER_DOMAIN * 6}\")\n",
    "    print(f\"   🔧 4bit量子化: {'有効' if USE_4BIT_QUANTIZATION else '無効'}\")\n",
    "    \n",
    "    print(f\"\\n🎯 対象ドメイン:\")\n",
    "    for i, domain in enumerate(DOMAINS, 1):\n",
    "        domain_name = DOMAIN_TEMPLATES[domain]['name']\n",
    "        print(f\"   {i}. {domain_name}\")\n",
    "    \n",
    "    if merged_file and os.path.exists(merged_file):\n",
    "        # 最終データ確認\n",
    "        with open(merged_file, 'r', encoding='utf-8') as f:\n",
    "            final_data = json.load(f)\n",
    "        \n",
    "        domain_counts = Counter(item['domain'] for item in final_data)\n",
    "        \n",
    "        print(f\"\\n✅ 生成結果:\")\n",
    "        print(f\"   📂 統合データ: {os.path.basename(merged_file)}\")\n",
    "        if sharegpt_file and os.path.exists(sharegpt_file):\n",
    "            print(f\"   📂 ShareGPT形式: {os.path.basename(sharegpt_file)}\")\n",
    "        print(f\"   📊 総問題数: {len(final_data)}\")\n",
    "        \n",
    "        print(f\"\\n📈 ドメイン別結果:\")\n",
    "        success_domains = 0\n",
    "        for domain in DOMAINS:\n",
    "            count = domain_counts.get(domain, 0)\n",
    "            domain_name = DOMAIN_TEMPLATES[domain]['name']\n",
    "            status = \"✅\" if count > 0 else \"❌\"\n",
    "            print(f\"   {status} {domain_name}: {count}問題\")\n",
    "            if count > 0:\n",
    "                success_domains += 1\n",
    "        \n",
    "        success_rate = (success_domains / len(DOMAINS)) * 100\n",
    "        print(f\"\\n🎯 成功率: {success_domains}/{len(DOMAINS)} ドメイン ({success_rate:.0f}%)\")\n",
    "        \n",
    "        if success_rate == 100:\n",
    "            print(\"\\n🏆 全ドメイン生成成功！\")\n",
    "        elif success_rate >= 80:\n",
    "            print(\"\\n🎉 高い成功率で完了！\")\n",
    "        else:\n",
    "            print(\"\\n⚠️ 一部のドメインで生成に失敗\")\n",
    "    else:\n",
    "        print(\"\\n❌ 統合データファイルが見つかりません\")\n",
    "    \n",
    "    print(f\"\\n💡 T4 GPU最適化版の特徴:\")\n",
    "    print(f\"   ✅ vLLM不要のTransformersベース\")\n",
    "    print(f\"   ✅ 4bit量子化でメモリ使用量削減\")\n",
    "    print(f\"   ✅ Google Colab T4で確実動作\")\n",
    "    print(f\"   ✅ 高品質なQwen2.5-3Bモデル使用\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✨ Google Colab軽量版完了 ✨\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# サマリー表示\n",
    "print_execution_summary()"
   ]
  }
 ],
 "metadata": {
  \"accelerator\": \"GPU\",\n  \"colab\": {\n   \"gpuType\": \"T4\",\n   \"provenance\": []\n  },\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"name\": \"python\"\n  }\n }\n}