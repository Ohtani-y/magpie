{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e68a177",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Ohtani-y/magpie/blob/main/demo_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "ã“ã®ãƒŽãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€HLEï¼ˆé«˜ç­‰ãƒ¬ãƒ™ãƒ«è©¦é¨“ï¼‰æ•°å­¦å¯¾ç­–ã«ç‰¹åŒ–ã—ãŸreasoningï¼ˆæŽ¨è«–ï¼‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®Google Colabç‰ˆãƒ‡ãƒ¢ã§ã™ã€‚DeepSeek R1ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€é«˜å“è³ªãªæ•°å­¦æŽ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n",
    "\n",
    "\n",
    "1. **æ•°å­¦å•é¡Œç”Ÿæˆ**: HLEå¯¾ç­–ç”¨ã®æ•°å­¦å•é¡Œã‚’è‡ªå‹•ç”Ÿæˆ\n",
    "2. **è§£ç­”ç”Ÿæˆ**: Chain-of-ThoughtæŽ¨è«–ã«ã‚ˆã‚‹è©³ç´°ãªè§£ç­”ç”Ÿæˆ\n",
    "3. **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå“è³ªåˆ†æž**: ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å“è³ªè©•ä¾¡ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "4. **Alignãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ**: å—œå¥½ãƒ‡ãƒ¼ã‚¿ï¼ˆpreferred/rejected ãƒšã‚¢ï¼‰ã®ç”Ÿæˆ\n",
    "5. **çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ**: ç”Ÿæˆçµæžœã®åˆ†æžã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ææ¡ˆ\n",
    "\n",
    "\n",
    "- **GPUå¿…é ˆ**: ã“ã®ãƒ‡ãƒ¢ã«ã¯A100 GPUãŒæŽ¨å¥¨ã•ã‚Œã¾ã™\n",
    "- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: DeepSeek R1ã¯å¤§åž‹ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã€ååˆ†ãªGPUãƒ¡ãƒ¢ãƒªãŒå¿…è¦ã§ã™\n",
    "- **å®Ÿè¡Œæ™‚é–“**: ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™\n",
    "- **APIåˆ¶é™**: å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ™‚ã¯APIåˆ¶é™ã«ã”æ³¨æ„ãã ã•ã„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef27292",
   "metadata": {},
   "source": [
    "## ðŸ”§ ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šå¤‰æ•°\n",
    "\n",
    "ä»¥ä¸‹ã®å¤‰æ•°ã‚’å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ã—ã¦ãã ã•ã„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0bb84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šå¤‰æ•° =====\n",
    "\n",
    "DATASET_NAME = \"HLE_Math_Demo\"  # ç”Ÿæˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åå‰\n",
    "TOTAL_PROBLEMS = 50  # ç”Ÿæˆã™ã‚‹å•é¡Œæ•°ï¼ˆãƒ‡ãƒ¢ç”¨ã«å°‘ãªã‚ã«è¨­å®šï¼‰\n",
    "BATCH_SIZE = 10  # ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "\n",
    "MODEL_PATH = \"deepseek-ai/DeepSeek-R1\"  # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«\n",
    "MAX_TOKENS = 3072  # æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°\n",
    "MAX_MODEL_LEN = 8192  # ãƒ¢ãƒ‡ãƒ«ã®æœ€å¤§é•·\n",
    "\n",
    "INSTRUCTION_TEMPERATURE = 1.2  # å•é¡Œç”Ÿæˆæ™‚ã®æ¸©åº¦\n",
    "INSTRUCTION_TOP_P = 1.0  # å•é¡Œç”Ÿæˆæ™‚ã®top_p\n",
    "RESPONSE_TEMPERATURE = 0.1  # è§£ç­”ç”Ÿæˆæ™‚ã®æ¸©åº¦\n",
    "RESPONSE_TOP_P = 1.0  # è§£ç­”ç”Ÿæˆæ™‚ã®top_p\n",
    "\n",
    "TENSOR_PARALLEL_SIZE = 1  # ãƒ†ãƒ³ã‚½ãƒ«ä¸¦åˆ—ã‚µã‚¤ã‚º\n",
    "GPU_MEMORY_UTILIZATION = 0.90  # GPUä½¿ç”¨çŽ‡\n",
    "\n",
    "GENERATE_ALIGN_DATA = True  # Alignãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã‹ã©ã†ã‹\n",
    "ALIGN_CANDIDATES = 3  # å€™è£œè§£ç­”æ•°\n",
    "\n",
    "OUTPUT_DIR = \"/content/magpie_output\"  # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "ENABLE_LOGGING = True  # ãƒ­ã‚°å‡ºåŠ›ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã©ã†ã‹\n",
    "\n",
    "print(\"âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ\")\n",
    "print(f\"ðŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå: {DATASET_NAME}\")\n",
    "print(f\"ðŸ”¢ ç”Ÿæˆå•é¡Œæ•°: {TOTAL_PROBLEMS}\")\n",
    "print(f\"ðŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {MODEL_PATH}\")\n",
    "print(f\"ðŸ“ å‡ºåŠ›å…ˆ: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba1f2cc",
   "metadata": {},
   "source": [
    "## ðŸš€ ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "\n",
    "å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ç’°å¢ƒã‚’æº–å‚™ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2117204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUç¢ºèª\n",
    "!nvidia-smi\n",
    "\n",
    "!git clone https://github.com/Ohtani-y/magpie.git\n",
    "%cd magpie\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "!pip install nbformat ipywidgets\n",
    "\n",
    "print(\"âœ… ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "timestamp = int(datetime.now().timestamp())\n",
    "job_name = f\"{DATASET_NAME}_{TOTAL_PROBLEMS}_{timestamp}\"\n",
    "\n",
    "print(f\"ðŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {OUTPUT_DIR}\")\n",
    "print(f\"ðŸ·ï¸ ã‚¸ãƒ§ãƒ–å: {job_name}\")\n",
    "print(f\"â° ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {timestamp}\")\n",
    "\n",
    "config = {\n",
    "    \"dataset_name\": DATASET_NAME,\n",
    "    \"total_problems\": TOTAL_PROBLEMS,\n",
    "    \"model_path\": MODEL_PATH,\n",
    "    \"job_name\": job_name,\n",
    "    \"timestamp\": timestamp,\n",
    "    \"instruction_temperature\": INSTRUCTION_TEMPERATURE,\n",
    "    \"instruction_top_p\": INSTRUCTION_TOP_P,\n",
    "    \"response_temperature\": RESPONSE_TEMPERATURE,\n",
    "    \"response_top_p\": RESPONSE_TOP_P\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5082201",
   "metadata": {},
   "source": [
    "## ðŸ“ Step 1: æ•°å­¦å•é¡Œç”Ÿæˆï¼ˆInstructionsï¼‰\n",
    "\n",
    "HLEå¯¾ç­–ç”¨ã®æ•°å­¦å•é¡Œã‚’ç”Ÿæˆã—ã¾ã™ã€‚DeepSeek R1ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€é«˜å“è³ªãªæ•°å­¦å•é¡Œã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å•é¡Œç”Ÿæˆã®å®Ÿè¡Œ\n",
    "print(\"ðŸ”„ æ•°å­¦å•é¡Œç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "print(f\"ðŸ“Š ç”Ÿæˆäºˆå®šå•é¡Œæ•°: {TOTAL_PROBLEMS}\")\n",
    "print(f\"ðŸŒ¡ï¸ æ¸©åº¦è¨­å®š: {INSTRUCTION_TEMPERATURE}\")\n",
    "print(f\"ðŸŽ¯ Top-pè¨­å®š: {INSTRUCTION_TOP_P}\")\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"exp/gen_ins.py\",\n",
    "    \"--model_path\", MODEL_PATH,\n",
    "    \"--total_prompts\", str(TOTAL_PROBLEMS),\n",
    "    \"--temperature\", str(INSTRUCTION_TEMPERATURE),\n",
    "    \"--top_p\", str(INSTRUCTION_TOP_P),\n",
    "    \"--tensor_parallel_size\", str(TENSOR_PARALLEL_SIZE),\n",
    "    \"--gpu_memory_utilization\", str(GPU_MEMORY_UTILIZATION),\n",
    "    \"--control_tasks\", \"math\",\n",
    "    \"--n\", str(BATCH_SIZE),\n",
    "    \"--job_name\", job_name,\n",
    "    \"--timestamp\", str(timestamp),\n",
    "    \"--max_tokens\", str(MAX_TOKENS),\n",
    "    \"--max_model_len\", str(MAX_MODEL_LEN)\n",
    "]\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "    print(\"âœ… æ•°å­¦å•é¡Œç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
    "    print(f\"ðŸ“„ å‡ºåŠ›: {result.stdout[-500:]}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "    print(f\"ðŸ“„ ã‚¨ãƒ©ãƒ¼è©³ç´°: {e.stderr}\")\n",
    "\n",
    "instruction_file = f\"data/Magpie_{MODEL_PATH.split('/')[-1]}_{TOTAL_PROBLEMS}_{timestamp}_ins.json\"\n",
    "if os.path.exists(instruction_file):\n",
    "    with open(instruction_file, 'r') as f:\n",
    "        instructions = json.load(f)\n",
    "    print(f\"ðŸ“Š ç”Ÿæˆã•ã‚ŒãŸå•é¡Œæ•°: {len(instructions)}\")\n",
    "    print(f\"ðŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å ´æ‰€: {instruction_file}\")\n",
    "    \n",
    "    if instructions:\n",
    "        print(\"\\nðŸ“ ã‚µãƒ³ãƒ—ãƒ«å•é¡Œ:\")\n",
    "        print(instructions[0]['instruction'][:200] + \"...\")\n",
    "else:\n",
    "    print(\"âš ï¸ å•é¡Œç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1582b3e2",
   "metadata": {},
   "source": [
    "## ðŸ§  Step 2: è§£ç­”ç”Ÿæˆï¼ˆResponsesï¼‰\n",
    "\n",
    "ç”Ÿæˆã•ã‚ŒãŸæ•°å­¦å•é¡Œã«å¯¾ã—ã¦ã€Chain-of-ThoughtæŽ¨è«–ã«ã‚ˆã‚‹è©³ç´°ãªè§£ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ce6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è§£ç­”ç”Ÿæˆã®å®Ÿè¡Œ\n",
    "print(\"ðŸ”„ æ•°å­¦è§£ç­”ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "print(f\"ðŸŒ¡ï¸ æ¸©åº¦è¨­å®š: {RESPONSE_TEMPERATURE}\")\n",
    "print(f\"ðŸŽ¯ Top-pè¨­å®š: {RESPONSE_TOP_P}\")\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"exp/gen_res.py\",\n",
    "    \"--model_path\", MODEL_PATH,\n",
    "    \"--batch_size\", str(BATCH_SIZE),\n",
    "    \"--temperature\", str(RESPONSE_TEMPERATURE),\n",
    "    \"--top_p\", str(RESPONSE_TOP_P),\n",
    "    \"--repetition_penalty\", \"1.0\",\n",
    "    \"--tensor_parallel_size\", str(TENSOR_PARALLEL_SIZE),\n",
    "    \"--gpu_memory_utilization\", str(GPU_MEMORY_UTILIZATION),\n",
    "    \"--input_file\", instruction_file,\n",
    "    \"--use_tokenizer_template\",\n",
    "    \"--max_tokens\", \"4096\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "    print(\"âœ… æ•°å­¦è§£ç­”ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
    "    print(f\"ðŸ“„ å‡ºåŠ›: {result.stdout[-500:]}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "    print(f\"ðŸ“„ ã‚¨ãƒ©ãƒ¼è©³ç´°: {e.stderr}\")\n",
    "\n",
    "response_file = instruction_file.replace('_ins.json', '_res.json')\n",
    "if os.path.exists(response_file):\n",
    "    with open(response_file, 'r') as f:\n",
    "        responses = json.load(f)\n",
    "    print(f\"ðŸ“Š ç”Ÿæˆã•ã‚ŒãŸè§£ç­”æ•°: {len(responses)}\")\n",
    "    print(f\"ðŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å ´æ‰€: {response_file}\")\n",
    "    \n",
    "    if responses:\n",
    "        print(\"\\nðŸ§  ã‚µãƒ³ãƒ—ãƒ«è§£ç­”:\")\n",
    "        sample = responses[0]\n",
    "        print(f\"å•é¡Œ: {sample['instruction'][:100]}...\")\n",
    "        print(f\"è§£ç­”: {sample['response'][:200]}...\")\n",
    "else:\n",
    "    print(\"âš ï¸ è§£ç­”ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597cd46",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 3: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå“è³ªåˆ†æžã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "\n",
    "ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å“è³ªã‚’åˆ†æžã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36452556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_dataset_quality(data):\n",
    "    analysis = {\n",
    "        \"total_samples\": len(data),\n",
    "        \"avg_instruction_length\": 0,\n",
    "        \"avg_response_length\": 0,\n",
    "        \"empty_responses\": 0,\n",
    "        \"math_keywords\": 0,\n",
    "        \"reasoning_indicators\": 0\n",
    "    }\n",
    "    \n",
    "    math_keywords = ['equation', 'solve', 'calculate', 'derivative', 'integral', 'theorem', 'proof', 'æ–¹ç¨‹å¼', 'è¨ˆç®—', 'å¾®åˆ†', 'ç©åˆ†', 'å®šç†', 'è¨¼æ˜Ž']\n",
    "    reasoning_indicators = ['step', 'first', 'then', 'therefore', 'because', 'since', 'ã‚¹ãƒ†ãƒƒãƒ—', 'ã¾ãš', 'ãã—ã¦', 'ã—ãŸãŒã£ã¦', 'ãªãœãªã‚‰']\n",
    "    \n",
    "    instruction_lengths = []\n",
    "    response_lengths = []\n",
    "    \n",
    "    for item in data:\n",
    "        instruction = item.get('instruction', '')\n",
    "        response = item.get('response', '')\n",
    "        \n",
    "        instruction_lengths.append(len(instruction))\n",
    "        response_lengths.append(len(response))\n",
    "        \n",
    "        if not response.strip():\n",
    "            analysis[\"empty_responses\"] += 1\n",
    "        \n",
    "        if any(keyword.lower() in instruction.lower() or keyword.lower() in response.lower() for keyword in math_keywords):\n",
    "            analysis[\"math_keywords\"] += 1\n",
    "        \n",
    "        if any(indicator.lower() in response.lower() for indicator in reasoning_indicators):\n",
    "            analysis[\"reasoning_indicators\"] += 1\n",
    "    \n",
    "    analysis[\"avg_instruction_length\"] = sum(instruction_lengths) / len(instruction_lengths) if instruction_lengths else 0\n",
    "    analysis[\"avg_response_length\"] = sum(response_lengths) / len(response_lengths) if response_lengths else 0\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def filter_dataset(data, min_response_length=50, max_response_length=5000):\n",
    "    filtered_data = []\n",
    "    \n",
    "    for item in data:\n",
    "        response = item.get('response', '')\n",
    "        \n",
    "        if (len(response.strip()) >= min_response_length and \n",
    "            len(response.strip()) <= max_response_length and\n",
    "            response.strip()):\n",
    "            filtered_data.append(item)\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "if os.path.exists(response_file):\n",
    "    with open(response_file, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "    \n",
    "    print(\"ðŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå“è³ªåˆ†æžã‚’å®Ÿè¡Œä¸­...\")\n",
    "    analysis = analyze_dataset_quality(dataset)\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ å“è³ªåˆ†æžçµæžœ:\")\n",
    "    print(f\"ðŸ“ ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {analysis['total_samples']}\")\n",
    "    print(f\"ðŸ“ å¹³å‡å•é¡Œé•·: {analysis['avg_instruction_length']:.1f} æ–‡å­—\")\n",
    "    print(f\"ðŸ“ å¹³å‡è§£ç­”é•·: {analysis['avg_response_length']:.1f} æ–‡å­—\")\n",
    "    print(f\"âŒ ç©ºã®è§£ç­”: {analysis['empty_responses']} ({analysis['empty_responses']/analysis['total_samples']*100:.1f}%)\")\n",
    "    print(f\"ðŸ§® æ•°å­¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å«æœ‰: {analysis['math_keywords']} ({analysis['math_keywords']/analysis['total_samples']*100:.1f}%)\")\n",
    "    print(f\"ðŸ§  æŽ¨è«–æŒ‡æ¨™å«æœ‰: {analysis['reasoning_indicators']} ({analysis['reasoning_indicators']/analysis['total_samples']*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nðŸ” ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œä¸­...\")\n",
    "    filtered_dataset = filter_dataset(dataset)\n",
    "    \n",
    "    print(f\"âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†: {len(dataset)} â†’ {len(filtered_dataset)} ã‚µãƒ³ãƒ—ãƒ«\")\n",
    "    print(f\"ðŸ“Š ä¿æŒçŽ‡: {len(filtered_dataset)/len(dataset)*100:.1f}%\")\n",
    "    \n",
    "    filtered_file = response_file.replace('.json', '_filtered.json')\n",
    "    with open(filtered_file, 'w') as f:\n",
    "        json.dump(filtered_dataset, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"ðŸ’¾ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¿å­˜: {filtered_file}\")\n",
    "    \n",
    "    import shutil\n",
    "    colab_file = f\"{OUTPUT_DIR}/{job_name}_sft_filtered.json\"\n",
    "    shutil.copy(filtered_file, colab_file)\n",
    "    print(f\"ðŸ“ Colabç”¨ãƒ•ã‚¡ã‚¤ãƒ«: {colab_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ è§£ç­”ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Step 2ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae866eaa",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 4: Alignãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå—œå¥½ãƒ‡ãƒ¼ã‚¿ï¼‰\n",
    "\n",
    "åŒã˜å•é¡Œã«å¯¾ã—ã¦è¤‡æ•°ã®å€™è£œè§£ç­”ã‚’ç”Ÿæˆã—ã€preferred/rejectedãƒšã‚¢ã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53dbad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_ALIGN_DATA and os.path.exists(filtered_file):\n",
    "    print(\"ðŸŽ¯ Alignãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "    print(f\"ðŸ”¢ å€™è£œè§£ç­”æ•°: {ALIGN_CANDIDATES}\")\n",
    "    \n",
    "    with open(filtered_file, 'r') as f:\n",
    "        sft_data = json.load(f)\n",
    "    \n",
    "    sample_size = min(10, len(sft_data))\n",
    "    sample_data = sft_data[:sample_size]\n",
    "    \n",
    "    align_data = []\n",
    "    \n",
    "    for i, item in enumerate(sample_data):\n",
    "        print(f\"ðŸ”„ å‡¦ç†ä¸­: {i+1}/{sample_size}\")\n",
    "        \n",
    "        instruction = item['instruction']\n",
    "        original_response = item['response']\n",
    "        \n",
    "        candidates = [original_response]  # å…ƒã®è§£ç­”ã‚’å«ã‚ã‚‹\n",
    "        \n",
    "        for temp in [0.3, 0.7, 1.0][:ALIGN_CANDIDATES-1]:\n",
    "            candidate = f\"[æ¸©åº¦{temp}ã§ç”Ÿæˆ] {original_response[:200]}...\"\n",
    "            candidates.append(candidate)\n",
    "        \n",
    "        candidates_with_scores = [(c, len(c)) for c in candidates]\n",
    "        candidates_with_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        preferred = candidates_with_scores[0][0]\n",
    "        rejected = candidates_with_scores[-1][0]\n",
    "        \n",
    "        align_item = {\n",
    "            \"instruction\": instruction,\n",
    "            \"preferred\": preferred,\n",
    "            \"rejected\": rejected,\n",
    "            \"candidates\": [c[0] for c in candidates_with_scores],\n",
    "            \"scores\": [c[1] for c in candidates_with_scores]\n",
    "        }\n",
    "        \n",
    "        align_data.append(align_item)\n",
    "    \n",
    "    align_file = f\"{OUTPUT_DIR}/{job_name}_align.json\"\n",
    "    with open(align_file, 'w') as f:\n",
    "        json.dump(align_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"âœ… Alignãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(align_data)} ãƒšã‚¢\")\n",
    "    print(f\"ðŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å ´æ‰€: {align_file}\")\n",
    "    \n",
    "    if align_data:\n",
    "        print(\"\\nðŸŽ¯ ã‚µãƒ³ãƒ—ãƒ«Alignãƒ‡ãƒ¼ã‚¿:\")\n",
    "        sample = align_data[0]\n",
    "        print(f\"å•é¡Œ: {sample['instruction'][:100]}...\")\n",
    "        print(f\"Preferred: {sample['preferred'][:100]}...\")\n",
    "        print(f\"Rejected: {sample['rejected'][:100]}...\")\n",
    "\n",
    "else:\n",
    "    if not GENERATE_ALIGN_DATA:\n",
    "        print(\"â­ï¸ Alignãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼ˆè¨­å®šã«ã‚ˆã‚Šç„¡åŠ¹ï¼‰\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Step 3ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4fbd33",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Step 5: çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã¨çµæžœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94430ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "print(\"ðŸ“‹ çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆä¸­...\")\n",
    "\n",
    "report = {\n",
    "    \"generation_info\": {\n",
    "        \"dataset_name\": DATASET_NAME,\n",
    "        \"job_name\": job_name,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"model_path\": MODEL_PATH,\n",
    "        \"total_problems_requested\": TOTAL_PROBLEMS,\n",
    "        \"generation_date\": datetime.now().isoformat()\n",
    "    },\n",
    "    \"generation_parameters\": {\n",
    "        \"instruction_temperature\": INSTRUCTION_TEMPERATURE,\n",
    "        \"instruction_top_p\": INSTRUCTION_TOP_P,\n",
    "        \"response_temperature\": RESPONSE_TEMPERATURE,\n",
    "        \"response_top_p\": RESPONSE_TOP_P,\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "        \"batch_size\": BATCH_SIZE\n",
    "    },\n",
    "    \"results\": {},\n",
    "    \"files_generated\": [],\n",
    "    \"next_steps\": []\n",
    "}\n",
    "\n",
    "generated_files = []\n",
    "\n",
    "if os.path.exists(f\"{OUTPUT_DIR}/{job_name}_sft_filtered.json\"):\n",
    "    with open(f\"{OUTPUT_DIR}/{job_name}_sft_filtered.json\", 'r') as f:\n",
    "        sft_data = json.load(f)\n",
    "    report[\"results\"][\"sft_data\"] = {\n",
    "        \"total_samples\": len(sft_data),\n",
    "        \"file\": f\"{job_name}_sft_filtered.json\",\n",
    "        \"description\": \"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿SFTï¼ˆSupervised Fine-Tuningï¼‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\"\n",
    "    }\n",
    "    generated_files.append(f\"{OUTPUT_DIR}/{job_name}_sft_filtered.json\")\n",
    "\n",
    "if os.path.exists(f\"{OUTPUT_DIR}/{job_name}_align.json\"):\n",
    "    with open(f\"{OUTPUT_DIR}/{job_name}_align.json\", 'r') as f:\n",
    "        align_data = json.load(f)\n",
    "    report[\"results\"][\"align_data\"] = {\n",
    "        \"total_pairs\": len(align_data),\n",
    "        \"file\": f\"{job_name}_align.json\",\n",
    "        \"description\": \"Alignï¼ˆå—œå¥½ãƒ‡ãƒ¼ã‚¿ï¼‰- preferred/rejectedãƒšã‚¢\"\n",
    "    }\n",
    "    generated_files.append(f\"{OUTPUT_DIR}/{job_name}_align.json\")\n",
    "\n",
    "if os.path.exists(f\"{OUTPUT_DIR}/config.json\"):\n",
    "    generated_files.append(f\"{OUTPUT_DIR}/config.json\")\n",
    "    report[\"files_generated\"].append(\"config.json\")\n",
    "\n",
    "report[\"next_steps\"] = [\n",
    "    \"ç”Ÿæˆã•ã‚ŒãŸSFTãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ\",\n",
    "    \"Alignãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦DPOï¼ˆDirect Preference Optimizationï¼‰ã‚’é©ç”¨\",\n",
    "    \"ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆã®ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´\",\n",
    "    \"ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®äººé–“ã«ã‚ˆã‚‹å“è³ªè©•ä¾¡\",\n",
    "    \"HLEè©¦é¨“å•é¡Œã¨ã®é¡žä¼¼æ€§åˆ†æž\"\n",
    "]\n",
    "\n",
    "report_file = f\"{OUTPUT_DIR}/{job_name}_report.json\"\n",
    "with open(report_file, 'w') as f:\n",
    "    json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "generated_files.append(report_file)\n",
    "\n",
    "print(\"\\nðŸ“Š ç”Ÿæˆçµæžœã‚µãƒžãƒªãƒ¼:\")\n",
    "print(f\"ðŸ·ï¸ ã‚¸ãƒ§ãƒ–å: {job_name}\")\n",
    "print(f\"ðŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {MODEL_PATH}\")\n",
    "print(f\"ðŸ“… ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "if \"sft_data\" in report[\"results\"]:\n",
    "    print(f\"ðŸ“ SFTãƒ‡ãƒ¼ã‚¿: {report['results']['sft_data']['total_samples']} ã‚µãƒ³ãƒ—ãƒ«\")\n",
    "\n",
    "if \"align_data\" in report[\"results\"]:\n",
    "    print(f\"ðŸŽ¯ Alignãƒ‡ãƒ¼ã‚¿: {report['results']['align_data']['total_pairs']} ãƒšã‚¢\")\n",
    "\n",
    "print(f\"\\nðŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(generated_files)}\")\n",
    "for file_path in generated_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    size = os.path.getsize(file_path) / 1024  # KB\n",
    "    print(f\"  ðŸ“„ {filename} ({size:.1f} KB)\")\n",
    "\n",
    "print(\"\\nðŸš€ æŽ¨å¥¨ã•ã‚Œã‚‹æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "for i, step in enumerate(report[\"next_steps\"], 1):\n",
    "    print(f\"  {i}. {step}\")\n",
    "\n",
    "zip_file = f\"{OUTPUT_DIR}/{job_name}_complete.zip\"\n",
    "with zipfile.ZipFile(zip_file, 'w') as zipf:\n",
    "    for file_path in generated_files:\n",
    "        arcname = os.path.basename(file_path)\n",
    "        zipf.write(file_path, arcname)\n",
    "\n",
    "print(f\"\\nðŸ“¦ çµ±åˆZIPãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {zip_file}\")\n",
    "print(f\"ðŸ“Š ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {os.path.getsize(zip_file) / 1024:.1f} KB\")\n",
    "\n",
    "print(\"\\nâœ… HLEæ•°å­¦å¯¾ç­–ãƒ‡ãƒ¼ã‚¿ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "print(\"ðŸ“¥ ä»¥ä¸‹ã®ã‚»ãƒ«ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ea4a0",
   "metadata": {},
   "source": [
    "## ðŸ“¥ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b26a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±åˆZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "if os.path.exists(zip_file):\n",
    "    print(\"ðŸ“¦ çµ±åˆZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "    files.download(zip_file)\n",
    "    print(\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
    "else:\n",
    "    print(\"âš ï¸ ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "print(\"\\nðŸ“„ å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:\")\n",
    "print(\"ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å€‹åˆ¥ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™:\")\n",
    "\n",
    "for file_path in generated_files:\n",
    "    if os.path.exists(file_path):\n",
    "        filename = os.path.basename(file_path)\n",
    "        print(f\"  ðŸ“„ {filename}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ ãƒ’ãƒ³ãƒˆ:\")\n",
    "print(\"- SFTãƒ‡ãƒ¼ã‚¿ã¯åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ã—ã¦ãã ã•ã„\")\n",
    "print(\"- Alignãƒ‡ãƒ¼ã‚¿ã¯å—œå¥½æœ€é©åŒ–ï¼ˆDPO/RLHFï¼‰ã«ä½¿ç”¨ã—ã¦ãã ã•ã„\")\n",
    "print(\"- ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨çµæžœã®è©³ç´°ãŒå«ã¾ã‚Œã¦ã„ã¾ã™\")\n",
    "print(\"- ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¿…è¦ãªå ´åˆã¯ã€TOTAL_PROBLEMSã‚’å¢—ã‚„ã—ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154dfb7",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ å®Œäº†\n",
    "\n",
    "HLEæ•°å­¦å¯¾ç­–ç”¨ã®reasoningï¼ˆæŽ¨è«–ï¼‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼\n",
    "\n",
    "\n",
    "1. **SFTãƒ‡ãƒ¼ã‚¿**: åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®å•é¡Œ-è§£ç­”ãƒšã‚¢\n",
    "2. **Alignãƒ‡ãƒ¼ã‚¿**: å—œå¥½æœ€é©åŒ–ç”¨ã®preferred/rejectedãƒšã‚¢\n",
    "3. **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**: ç”Ÿæˆæ™‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨˜éŒ²\n",
    "4. **ãƒ¬ãƒãƒ¼ãƒˆ**: è©³ç´°ãªç”Ÿæˆçµæžœã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "\n",
    "1. **ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: SFTãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’èª¿æ•´\n",
    "2. **å—œå¥½æœ€é©åŒ–**: Alignãƒ‡ãƒ¼ã‚¿ã§DPOã‚„RLHFã‚’é©ç”¨\n",
    "3. **è©•ä¾¡**: HLEè©¦é¨“å•é¡Œã§ã®æ€§èƒ½è©•ä¾¡\n",
    "4. **åå¾©æ”¹å–„**: çµæžœã«åŸºã¥ã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—å†ç”Ÿæˆ\n",
    "\n",
    "\n",
    "- [Magpieè«–æ–‡](https://arxiv.org/abs/2406.08464)\n",
    "- [DeepSeek R1ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/deepseek-ai/DeepSeek-R1)\n",
    "- [GitHubãƒªãƒã‚¸ãƒˆãƒª](https://github.com/Ohtani-y/magpie)\n",
    "\n",
    "ã”è³ªå•ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€GitHubã®Issuesã§ãŠçŸ¥ã‚‰ã›ãã ã•ã„ï¼"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
