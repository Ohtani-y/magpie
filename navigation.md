# ğŸ§® Reasoningç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³

## HLEæ•°å­¦å¯¾ç­–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

### [**DeepSeek R1**](https://huggingface.co/deepseek-ai/DeepSeek-R1) - æ¨å¥¨
|ãƒ¢ãƒ‡ãƒ«å | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ã‚¿ã‚¤ãƒ— | èª¬æ˜ |
|-------------|:-------|:-------|:-------|
| [DeepSeek R1 685B](https://huggingface.co/deepseek-ai/DeepSeek-R1) | Magpie-DeepSeek-R1-Math-Reasoning | SFT | HLEæ•°å­¦å¯¾ç­–ã«ç‰¹åŒ–ã—ãŸé«˜å“è³ªæ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
| [DeepSeek R1 685B](https://huggingface.co/deepseek-ai/DeepSeek-R1) | Magpie-DeepSeek-R1-CoT-Math | SFT | Chain-of-Thoughtæ¨è«–ã‚’å«ã‚€æ•°å­¦å•é¡Œè§£æ±ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

### [**Meta Llama 3.1**](https://huggingface.co/collections/meta-llama/llama-31-669fc079a0c406a149a5738f)
|Model Name | Dataset | Type | Description |
|-------------|:-------|:-------|:-------|
| [Llama 3.1 70B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct) | [Magpie-Llama-3.1-Pro-1M](https://huggingface.co/datasets/Magpie-Align/Magpie-Llama-3.1-Pro-1M-v0.1) | SFT | 1M Raw conversations built with Meta Llama 3.1 70B.
| [Llama 3.1 70B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct) | [Magpie-Llama-3.1-Pro-300K-Filtered](https://huggingface.co/datasets/Magpie-Align/Magpie-Llama-3.1-Pro-300K-Filtered) | SFT | Apply a filter and select 300K high quality conversations.
| [Llama 3.1 70B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct) | [Magpie-Llama-3.1-Pro-500K-Filtered](https://huggingface.co/datasets/Magpie-Align/Magpie-Llama-3.1-Pro-500K-Filtered) | SFT | Apply a filter and select 500K high quality conversations.
| [Llama 3.1 70B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct) | [Magpie-Llama-3.1-Pro-MT-500K](https://huggingface.co/datasets/Magpie-Align/Magpie-Llama-3.1-Pro-MT-500K-v0.1) | SFT | Extend Magpie-Llama-3.1-Pro-500K-Filtered to multi-turn.
| [Llama 3.1 70B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct) | [Magpie-Llama-3.1-Pro-MT-300K-Filtered](https://huggingface.co/datasets/Magpie-Align/Magpie-Llama-3.1-Pro-MT-300K-Filtered) | SFT | Select 300K high quality multi-turn conversations from Magpie-Llama-3.1-Pro-MT-500K.
| [Llama 3.1 70B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct) | [Magpie-Llama-3.1-Pro-DPO-100K](https://huggingface.co/datasets/Magpie-Align/Magpie-Llama-3.1-Pro-DPO-100K-v0.1) | DPO | DPO dataset via Best-of-N sampling and rewards.

### [**Meta Llama 3**](https://huggingface.co/collections/meta-llama/meta-llama-3-66214712577ca38149ebb2b6)
|Model Name | Dataset | Type | Description |
|-------------|:-------|:-------|:-------|
| [Llama 3 70B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct) | [Magpie-Pro-1M](https://huggingface.co/datasets/Magpie-Align/Llama-3-Magpie-Pro-1M-v0.1) | SFT | 1M Raw conversations built with Meta Llama 3 70B.
| [Llama 3 70B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct) | [Magpie-Pro-300K-Filtered](https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-300K-Filtered) | SFT | Apply a filter and select 300K high quality conversations.
| [Llama 3 70B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct) | [Magpie-Pro-MT-300K](https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-MT-300K-v0.1) | SFT | Select 300K difficult questions and extend to multi-turn conversations.
| [Llama 3 70B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct) | [Magpie-Pro-DPO-100K](https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-DPO-100K-v0.1) | DPO | DPO dataset via Best-of-N sampling and rewards.
| [Llama 3 8B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) | [Magpie-Air-3M](https://huggingface.co/datasets/Magpie-Align/Llama-3-Magpie-Air-3M-v0.1) | SFT | 3M Raw conversations built with Meta Llama 3 8B.
| [Llama 3 8B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) | [Magpie-Air-300K-Filtered](https://huggingface.co/datasets/Magpie-Align/Magpie-Air-300K-Filtered) | SFT | Apply a filter and select 300K high quality data.
| [Llama 3 8B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) | [Magpie-Air-MT-300K](https://huggingface.co/datasets/Magpie-Align/Magpie-Air-MT-300K-v0.1) | SFT | Select 300K difficult questions and extend to multi-turn conversations.
| [Llama 3 8B Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) | [Magpie-Air-DPO-100K](https://huggingface.co/datasets/Magpie-Align/Magpie-Air-DPO-100K-v0.1) | DPO | DPO dataset via Best-of-N sampling and rewards.

### [**Qwen2.5**](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e)
|Model Name | Dataset | Type | Description |
|-------------|:-------|:-------|:-------|
| [Qwen2.5 72B Instruct](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct) | [Magpie-Qwen2.5-Pro-1M](https://huggingface.co/datasets/Magpie-Align/Magpie-Qwen2.5-Pro-1M-v0.1) | SFT | 1M Raw conversations built with Qwen2.5 72B Instruct.
| [Qwen2.5 72B Instruct](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct) | [Magpie-Qwen2.5-Pro-300K-Filtered](https://huggingface.co/datasets/Magpie-Align/Magpie-Qwen2.5-Pro-300K-Filtered) | SFT | Apply a filter and select 300K high quality conversations.

### [**Qwen2**](https://huggingface.co/collections/Qwen/qwen2-6659360b33528ced941e557f)
|Model Name | Dataset | Type | Description |
|-------------|:-------|:-------|:-------|
| [Qwen2 72B Instruct](https://huggingface.co/Qwen/Qwen2-72B-Instruct) | [Magpie-Qwen2-Pro-1M](https://huggingface.co/datasets/Magpie-Align/Magpie-Qwen2-Pro-1M-v0.1) | SFT | 1M Raw conversations built with Qwen2 72B Instruct.
| [Qwen2 72B Instruct](https://huggingface.co/Qwen/Qwen2-72B-Instruct) | [Magpie-Qwen2-Pro-300K-Filtered](https://huggingface.co/datasets/Magpie-Align/Magpie-Qwen2-Pro-300K-Filtered) | SFT | Apply a filter and select 300K high quality conversations.
| [Qwen2 72B Instruct](https://huggingface.co/Qwen/Qwen2-72B-Instruct) | [Magpie-Qwen2-Pro-200K-Chinese](https://huggingface.co/datasets/Magpie-Align/Magpie-Qwen2-Pro-200K-Chinese) | SFT | Apply a filter and select 200K high quality Chinese conversations.
| [Qwen2 72B Instruct](https://huggingface.co/Qwen/Qwen2-72B-Instruct) | [Magpie-Qwen2-Pro-200K-English](https://huggingface.co/datasets/Magpie-Align/Magpie-Qwen2-Pro-200K-English) | SFT | Apply a filter and select 200K high quality English conversations.
| [Qwen2 7B Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct) | [Magpie-Qwen2-Air-3M](https://huggingface.co/datasets/Magpie-Align/Magpie-Qwen2-Air-3M-v0.1) | SFT | 3M Raw conversations built with Qwen2 7B Instruct.
| [Qwen2 7B Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct) | [Magpie-Qwen2-Air-300K-Filtered](https://huggingface.co/datasets/Magpie-Align/Magpie-Qwen-Air-300K-Filtered) | SFT | Apply a filter and select 300K high quality conversations.

### [**Phi-3**](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3)
|Model Name | Dataset | Type | Description |
|-------------|:-------|:-------|:-------|
| [Phi-3 Medium Instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct) | [Magpie-Phi3-Pro-1M](https://huggingface.co/datasets/Magpie-Align/Magpie-Phi3-Pro-1M-v0.1) | SFT | 1M Raw conversations built with Phi-3 Medium Instruct.
| [Phi-3 Medium Instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct) | [Magpie-Phi3-Pro-300K-Filtered](https://huggingface.co/datasets/Magpie-Align/Magpie-Phi3-Pro-300K-Filtered) | SFT | Apply a filter and select 300K high quality conversations.

### [**Gemma-2**](https://huggingface.co/collections/google/gemma-2-release-667d6600fd5220e7b967f315)
|Model Name | Dataset | Type | Description |
|-------------|:-------|:-------|:-------|
| [Gemma-2-27b-it](https://huggingface.co/google/gemma-2-27b-it) | [Magpie-Gemma2-Pro-534K](https://huggingface.co/datasets/Magpie-Align/Magpie-Gemma2-Pro-534K-v0.1) | SFT | 534K conversations built with Gemma-2-27b-it.
| [Gemma-2-27b-it](https://huggingface.co/google/gemma-2-27b-it) | [Magpie-Gemma2-Pro-200K-Filtered](https://huggingface.co/datasets/Magpie-Align/Magpie-Gemma2-Pro-200K-Filtered) | SFT | Apply a filter and select 200K conversations.

---

## Domain Datasets

### ğŸ§  CoTæ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
|ãƒ¢ãƒ‡ãƒ« | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ã‚¿ã‚¤ãƒ— | èª¬æ˜ |
|-------------|:-------|:-------|:-------|
| DeepSeek R1 (å•é¡Œç”Ÿæˆ) + DeepSeek R1 (è§£ç­”ç”Ÿæˆ) | [Magpie-Reasoning-V3-DeepSeek-R1-Math](https://huggingface.co/datasets/Magpie-Align/Magpie-Reasoning-V3-DeepSeek-R1-Math) | SFT | HLEæ•°å­¦å¯¾ç­–ã«ç‰¹åŒ–ã—ãŸDeepSeek R1ã«ã‚ˆã‚‹é«˜å“è³ªæ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
| Qwen2-72B-Instruct (å•é¡Œ) + DeepSeek R1 (è§£ç­”) | [Magpie-Reasoning-V1-150K-CoT-Deepseek-R1-Llama-70B](https://huggingface.co/datasets/Magpie-Align/Magpie-Reasoning-V1-150K-CoT-Deepseek-R1-Llama-70B) | SFT | 150Kä»¶ã®Qwen2å•é¡Œã¨DeepSeek R1è§£ç­”ã®çµ„ã¿åˆã‚ã›
| Llama3.1/3.3-70B-Instruct (å•é¡Œ) + DeepSeek R1 (è§£ç­”) | [Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B](https://huggingface.co/datasets/Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B) | SFT | 250Kä»¶ã®Llama3å•é¡Œã¨DeepSeek R1è§£ç­”ã®çµ„ã¿åˆã‚ã›


## ğŸ¯ HLEå¯¾ç­–æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ„ã¿åˆã‚ã›

### åŸºæœ¬ã‚»ãƒƒãƒˆï¼ˆåˆç´šã€œä¸­ç´šï¼‰
- **Magpie-Qwen2-Math-Lightweight-100K**: åŸºç¤æ•°å­¦å•é¡Œ
- **Magpie-Algebra-HLE-50K**: ä»£æ•°å­¦å¼·åŒ–
- **Magpie-Geometry-HLE-30K**: å¹¾ä½•å­¦åŸºç¤

### æ¨™æº–ã‚»ãƒƒãƒˆï¼ˆä¸­ç´šã€œä¸Šç´šï¼‰
- **Magpie-DeepSeek-R1-HLE-Math-500K**: ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- **Magpie-Calculus-HLE-50K**: å¾®ç©åˆ†å­¦
- **Magpie-Statistics-HLE-30K**: çµ±è¨ˆå­¦

### å®Œå…¨ã‚»ãƒƒãƒˆï¼ˆä¸Šç´šã€œæœ€é«˜ãƒ¬ãƒ™ãƒ«ï¼‰
- **Magpie-DeepSeek-R1-HLE-Math-500K**: ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- **å…¨åˆ†é‡åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: 180Kä»¶ã®å°‚é–€å•é¡Œ
- **Magpie-Reasoning-V3-DeepSeek-R1-Math**: CoTæ¨è«–å¼·åŒ–

## ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå“è³ªæŒ‡æ¨™

|å“è³ªãƒ¬ãƒ™ãƒ« | ç‰¹å¾´ | æ¨å¥¨ç”¨é€” |
|-------------|:-------|:-------|
| â­â­â­â­â­ | DeepSeek R1ç”Ÿæˆã€CoTæ¨è«–ã€HLEç‰¹åŒ– | æœ€é«˜ãƒ¬ãƒ™ãƒ«è©¦é¨“å¯¾ç­–
| â­â­â­â­ | æ•°å­¦ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã€æ®µéšçš„è§£æ³• | ä¸Šç´šè©¦é¨“å¯¾ç­–
| â­â­â­ | æ±ç”¨ãƒ¢ãƒ‡ãƒ«+æ•°å­¦ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ | ä¸­ç´šè©¦é¨“å¯¾ç­–

### ğŸ“ æ•°å­¦ç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

|ãƒ¢ãƒ‡ãƒ« | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ã‚¿ã‚¤ãƒ— | èª¬æ˜ |
|-------------|:-------|:-------|:-------|
| [DeepSeek R1](https://huggingface.co/deepseek-ai/DeepSeek-R1) | Magpie-DeepSeek-R1-HLE-Math-500K | SFT | HLEå¯¾ç­–ã«ç‰¹åŒ–ã—ãŸ500Kä»¶ã®æ•°å­¦æ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
| [Qwen2.5 Math 72B](https://huggingface.co/Qwen/Qwen2.5-Math-72B-Instruct) | [Magpie-Qwen2.5-Math-Pro-300K-v0.1](https://huggingface.co/datasets/Magpie-Align/Magpie-Qwen2.5-Math-Pro-300K-v0.1) | SFT | Qwen2.5 Math 72Bã«ã‚ˆã‚‹300Kä»¶ã®æ•°å­¦å¯¾è©±ãƒ‡ãƒ¼ã‚¿
| [Qwen2 Math 7B](https://huggingface.co/Qwen/Qwen2-Math-7B-Instruct) | Magpie-Qwen2-Math-Lightweight-100K | SFT | è»½é‡ç‰ˆæ•°å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ100Kä»¶ï¼‰

### ğŸ“Š åˆ†é‡åˆ¥æ•°å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

|æ•°å­¦åˆ†é‡ | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | å•é¡Œæ•° | ç‰¹å¾´ |
|-------------|:-------|:-------|:-------|
| ä»£æ•°å­¦ (Algebra) | Magpie-Algebra-HLE-50K | 50K | äºŒæ¬¡æ–¹ç¨‹å¼ã€ä¸ç­‰å¼ã€é–¢æ•°ç­‰
| å¾®ç©åˆ†å­¦ (Calculus) | Magpie-Calculus-HLE-50K | 50K | æ¥µé™ã€å¾®åˆ†ã€ç©åˆ†ã€å¿œç”¨å•é¡Œ
| å¹¾ä½•å­¦ (Geometry) | Magpie-Geometry-HLE-30K | 30K | å¹³é¢ãƒ»ç«‹ä½“å¹¾ä½•ã€ä¸‰è§’æ³•
| çµ±è¨ˆå­¦ (Statistics) | Magpie-Statistics-HLE-30K | 30K | ç¢ºç‡ã€çµ±è¨ˆçš„æ¨è«–ã€ãƒ‡ãƒ¼ã‚¿åˆ†æ
| æ•°è«– (Number Theory) | Magpie-NumberTheory-HLE-20K | 20K | æ•´æ•°è«–ã€æš—å·ç†è«–åŸºç¤
