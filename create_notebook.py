import json
import nbformat as nbf

nb = nbf.v4.new_notebook()

cells = [
    nbf.v4.new_markdown_cell('# 🧮 Magpie Reasoning - HLE数学対策特化版\n\nこのノートブックは、HLE（高等レベル試験）数学対策に特化したreasoning（推論）データセット生成システムの本番用統合環境です。\n\n## 🎯 機能\n- **DeepSeek R1による高品質数学推論データ生成**\n- **データセットフィルタリングとクリーニング**\n- **Alignデータ生成（嗜好データ生成）**\n- **HLE対策特化テンプレート**\n- **Chain-of-Thought推論サポート**'),
    
    nbf.v4.new_markdown_cell('## ⚙️ ユーザー設定変数\n\n以下の変数を必要に応じて変更してください：'),
    
    nbf.v4.new_code_cell('# =============================================================================\n# ユーザー設定変数 - 必要に応じて変更してください\n# =============================================================================\n\n# データセット設定\nDATASET_NAME = "HLE-Math-Reasoning-Dataset"  # 生成するデータセット名\nOUTPUT_DIR = "./data"  # 出力ディレクトリ\nTOTAL_PROBLEMS = 1000  # 生成する問題数\n\n# モデル設定\nMODEL_PATH = "deepseek-ai/DeepSeek-R1"  # 使用するモデル（DeepSeek R1推奨）\nDEVICE = "0"  # GPU デバイス番号\nTENSOR_PARALLEL = 4  # テンソル並列数（DeepSeek R1用）\nGPU_MEMORY_UTILIZATION = 0.90  # GPU メモリ使用率\n\n# 生成パラメータ\nINSTRUCTION_TEMPERATURE = 1.2  # 問題生成の創造性\nINSTRUCTION_TOP_P = 1.0  # 問題生成の多様性\nRESPONSE_TEMPERATURE = 0.1  # 解答生成の一貫性\nRESPONSE_TOP_P = 1.0  # 解答生成のバランス\n\n# フィルタリング設定\nMIN_INSTRUCTION_LENGTH = 20  # 最小問題文長\nMIN_RESPONSE_LENGTH = 50  # 最小解答長\nMAX_INSTRUCTION_LENGTH = 1000  # 最大問題文長\nMAX_RESPONSE_LENGTH = 4000  # 最大解答長\nQUALITY_THRESHOLD = 0.7  # 品質スコア閾値\n\n# Alignデータ生成設定\nENABLE_ALIGN_DATA = True  # Alignデータ生成を有効にする\nALIGN_CANDIDATES = 4  # Alignデータ用候補解答数\nALIGN_TEMPERATURE = 0.8  # Alignデータ候補生成温度\n\n# HLE特化設定\nMATH_DOMAINS = ["algebra", "calculus", "geometry", "statistics", "number_theory"]  # 対象数学分野\nDIFFICULTY_LEVELS = ["intermediate", "advanced", "expert"]  # 難易度レベル\n\nprint(f"📊 設定完了: {DATASET_NAME} - {TOTAL_PROBLEMS}問題を生成")\nprint(f"🤖 使用モデル: {MODEL_PATH}")\nprint(f"🎯 対象分野: {\", \".join(MATH_DOMAINS)}")'),
    
    nbf.v4.new_markdown_cell('## 📦 必要なライブラリのインポート'),
    
    nbf.v4.new_code_cell('import os\nimport sys\nimport json\nimport time\nimport random\nimport subprocess\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom typing import List, Dict, Any, Optional\n\n# Magpie関連のインポート\nsys.path.insert(0, os.path.abspath("."))\nsys.path.insert(0, os.path.abspath("./exp"))\n\n# 出力ディレクトリの作成\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nprint(f"📁 出力ディレクトリ準備完了: {OUTPUT_DIR}")'),
    
    nbf.v4.new_markdown_cell('## 🔧 ユーティリティ関数'),
    
    nbf.v4.new_code_cell('def create_job_name(prefix="HLE-Math"):\n    """ジョブ名を生成する"""\n    timestamp = int(time.time())\n    return f"{prefix}_{TOTAL_PROBLEMS}_{timestamp}"\n\ndef setup_logging(job_name):\n    """ログ設定を行う"""\n    log_dir = Path(OUTPUT_DIR) / job_name\n    log_dir.mkdir(parents=True, exist_ok=True)\n    return log_dir\n\ndef run_magpie_generation(script_type, **kwargs):\n    """Magpie生成スクリプトを実行する"""\n    try:\n        if script_type == "instruction":\n            cmd = [\n                "python", "exp/gen_ins.py",\n                "--model_path", kwargs.get("model_path", MODEL_PATH),\n                "--total_prompts", str(kwargs.get("total_prompts", TOTAL_PROBLEMS)),\n                "--temperature", str(kwargs.get("temperature", INSTRUCTION_TEMPERATURE)),\n                "--top_p", str(kwargs.get("top_p", INSTRUCTION_TOP_P)),\n                "--tensor_parallel_size", str(kwargs.get("tensor_parallel_size", TENSOR_PARALLEL)),\n                "--gpu_memory_utilization", str(kwargs.get("gpu_memory_utilization", GPU_MEMORY_UTILIZATION)),\n                "--control_tasks", "math",\n                "--device", str(kwargs.get("device", DEVICE)),\n                "--job_name", kwargs.get("job_name", "default"),\n                "--timestamp", str(kwargs.get("timestamp", int(time.time()))),\n                "--n", str(kwargs.get("n", 50)),\n                "--max_tokens", str(kwargs.get("max_tokens", 3072)),\n                "--max_model_len", str(kwargs.get("max_model_len", 8192))\n            ]\n        elif script_type == "response":\n            cmd = [\n                "python", "exp/gen_res.py",\n                "--model_path", kwargs.get("model_path", MODEL_PATH),\n                "--input_file", kwargs.get("input_file", ""),\n                "--temperature", str(kwargs.get("temperature", RESPONSE_TEMPERATURE)),\n                "--top_p", str(kwargs.get("top_p", RESPONSE_TOP_P)),\n                "--tensor_parallel_size", str(kwargs.get("tensor_parallel_size", TENSOR_PARALLEL)),\n                "--gpu_memory_utilization", str(kwargs.get("gpu_memory_utilization", GPU_MEMORY_UTILIZATION)),\n                "--device", str(kwargs.get("device", DEVICE)),\n                "--batch_size", str(kwargs.get("batch_size", 50)),\n                "--repetition_penalty", str(kwargs.get("repetition_penalty", 1.0)),\n                "--use_tokenizer_template",\n                "--offline",\n                "--max_tokens", str(kwargs.get("max_tokens", 4096))\n            ]\n        else:\n            raise ValueError(f"未知のスクリプトタイプ: {script_type}")\n        \n        print(f"🚀 実行コマンド: {\" \".join(cmd)}")\n        result = subprocess.run(cmd, capture_output=True, text=True, cwd=".")\n        \n        if result.returncode == 0:\n            print(f"✅ {script_type}生成が正常に完了しました")\n            return True, result.stdout\n        else:\n            print(f"❌ {script_type}生成でエラーが発生しました")\n            print(f"エラー出力: {result.stderr}")\n            return False, result.stderr\n            \n    except Exception as e:\n        print(f"❌ {script_type}生成で例外が発生しました: {e}")\n        return False, str(e)\n\nprint("🔧 ユーティリティ関数が準備完了")'),
    
    nbf.v4.new_markdown_cell('## 🚀 Step 1: HLE数学問題生成'),
    
    nbf.v4.new_code_cell('print("🧮 HLE数学問題生成を開始...")\n\n# ジョブ設定\njob_name = create_job_name("DeepSeek-R1-HLE-Math")\nlog_dir = setup_logging(job_name)\ntimestamp = int(time.time())\n\nprint(f"📝 ジョブ名: {job_name}")\nprint(f"📁 ログディレクトリ: {log_dir}")\n\n# 問題生成の実行\ninstruction_success, instruction_output = run_magpie_generation(\n    "instruction",\n    model_path=MODEL_PATH,\n    total_prompts=TOTAL_PROBLEMS,\n    temperature=INSTRUCTION_TEMPERATURE,\n    top_p=INSTRUCTION_TOP_P,\n    tensor_parallel_size=TENSOR_PARALLEL,\n    gpu_memory_utilization=GPU_MEMORY_UTILIZATION,\n    device=DEVICE,\n    job_name=job_name,\n    timestamp=timestamp,\n    n=50,\n    max_tokens=3072,\n    max_model_len=8192\n)\n\nif instruction_success:\n    # 生成されたファイルを探す\n    model_name = MODEL_PATH.split("/")[-1]\n    instructions_file = log_dir / f"Magpie_{model_name}_{TOTAL_PROBLEMS}_{timestamp}_ins.json"\n    \n    if instructions_file.exists():\n        with open(instructions_file, "r", encoding="utf-8") as f:\n            instructions_data = json.load(f)\n        \n        print(f"✅ 数学問題生成完了: {len(instructions_data)}問題")\n        print(f"💾 保存先: {instructions_file}")\n    else:\n        print(f"⚠️ 期待されるファイルが見つかりません: {instructions_file}")\n        files = list(log_dir.glob("*_ins.json"))\n        if files:\n            instructions_file = files[0]\n            print(f"📁 代替ファイルを使用: {instructions_file}")\n        else:\n            instructions_file = None\nelse:\n    print(f"❌ 問題生成に失敗しました: {instruction_output}")\n    instructions_file = None'),
    
    nbf.v4.new_markdown_cell('## 🎯 Step 2: 数学解答生成'),
    
    nbf.v4.new_code_cell('if instructions_file and instructions_file.exists():\n    print("🎯 HLE数学解答生成を開始...")\n    \n    # 解答生成の実行\n    response_success, response_output = run_magpie_generation(\n        "response",\n        model_path=MODEL_PATH,\n        input_file=str(instructions_file),\n        temperature=RESPONSE_TEMPERATURE,\n        top_p=RESPONSE_TOP_P,\n        tensor_parallel_size=TENSOR_PARALLEL,\n        gpu_memory_utilization=GPU_MEMORY_UTILIZATION,\n        device=DEVICE,\n        batch_size=50,\n        repetition_penalty=1.0,\n        max_tokens=4096\n    )\n    \n    if response_success:\n        # 生成されたファイルを探す\n        responses_files = list(log_dir.glob("*_ins_res.json"))\n        if responses_files:\n            responses_file = responses_files[0]\n            \n            with open(responses_file, "r", encoding="utf-8") as f:\n                responses_data = json.load(f)\n            \n            print(f"✅ 数学解答生成完了: {len(responses_data)}解答")\n            print(f"💾 保存先: {responses_file}")\n        else:\n            print("⚠️ 解答ファイルが見つかりません")\n            responses_file = None\n    else:\n        print(f"❌ 解答生成に失敗しました: {response_output}")\n        responses_file = None\nelse:\n    print("⚠️ 問題ファイルが見つかりません。Step 1を先に実行してください。")\n    responses_file = None'),
    
    nbf.v4.new_markdown_cell('## 🔍 Step 3: データセット品質分析とフィルタリング'),
    
    nbf.v4.new_code_cell('def validate_dataset(data):\n    """データセットの品質を検証する"""\n    if not data:\n        return False, "データセットが空です"\n    \n    valid_count = 0\n    issues = []\n    \n    for i, item in enumerate(data):\n        # 必須フィールドの確認\n        if "instruction" not in item or "response" not in item:\n            issues.append(f"項目 {i}: 必須フィールドが不足")\n            continue\n            \n        # 長さの確認\n        inst_len = len(item["instruction"])\n        resp_len = len(item["response"])\n        \n        if inst_len < MIN_INSTRUCTION_LENGTH or inst_len > MAX_INSTRUCTION_LENGTH:\n            issues.append(f"項目 {i}: 問題文長が範囲外 ({inst_len})")\n            continue\n            \n        if resp_len < MIN_RESPONSE_LENGTH or resp_len > MAX_RESPONSE_LENGTH:\n            issues.append(f"項目 {i}: 解答長が範囲外 ({resp_len})")\n            continue\n            \n        valid_count += 1\n    \n    success_rate = valid_count / len(data) if data else 0\n    return success_rate >= QUALITY_THRESHOLD, f"有効率: {success_rate:.2%}, 問題: {len(issues)}"\n\ndef filter_dataset(data):\n    """データセットをフィルタリングする"""\n    filtered_data = []\n    \n    for item in data:\n        if ("instruction" in item and "response" in item and\n            MIN_INSTRUCTION_LENGTH <= len(item["instruction"]) <= MAX_INSTRUCTION_LENGTH and\n            MIN_RESPONSE_LENGTH <= len(item["response"]) <= MAX_RESPONSE_LENGTH):\n            filtered_data.append(item)\n    \n    return filtered_data\n\nif responses_file and responses_file.exists():\n    print("🔍 データセット品質分析を開始...")\n    \n    # データセットの読み込み\n    with open(responses_file, "r", encoding="utf-8") as f:\n        raw_dataset = json.load(f)\n    \n    print(f"📊 生データセット: {len(raw_dataset)}項目")\n    \n    # 品質検証\n    is_valid, validation_msg = validate_dataset(raw_dataset)\n    print(f"🔍 品質検証結果: {validation_msg}")\n    \n    # フィルタリング実行\n    print("\\n🧹 データセットフィルタリング実行中...")\n    filtered_dataset = filter_dataset(raw_dataset)\n    \n    print(f"✅ フィルタリング完了: {len(raw_dataset)} → {len(filtered_dataset)}項目")\n    \n    # フィルタリング済みデータセットを保存\n    filtered_file = log_dir / f"Magpie_{MODEL_PATH.split(\"/\")[-1]}_filtered_{len(filtered_dataset)}.json"\n    with open(filtered_file, "w", encoding="utf-8") as f:\n        json.dump(filtered_dataset, f, ensure_ascii=False, indent=2)\n    \n    print(f"💾 フィルタリング済みデータセット保存: {filtered_file}")\n    \nelse:\n    print("⚠️ 解答ファイルが見つかりません。Step 2を先に実行してください。")\n    filtered_dataset = None\n    filtered_file = None'),
    
    nbf.v4.new_markdown_cell('## 🎯 Step 4: Alignデータ生成（嗜好データ生成）'),
    
    nbf.v4.new_code_cell('def generate_align_candidates(instruction, num_candidates=ALIGN_CANDIDATES):\n    """Alignデータ用の複数候補解答を生成する（本番実装）"""\n    candidates = []\n    \n    # 実際の実装では、VLLMを使用して異なる温度設定で複数の解答を生成\n    for i in range(num_candidates):\n        # 温度を変えて多様な解答を生成\n        temp = ALIGN_TEMPERATURE + (i * 0.1)\n        \n        # 本番実装では以下のようにVLLMを使用\n        # try:\n        #     llm = LLM(model=MODEL_PATH, tensor_parallel_size=TENSOR_PARALLEL)\n        #     sampling_params = SamplingParams(temperature=temp, top_p=RESPONSE_TOP_P, max_tokens=4096)\n        #     outputs = llm.generate([instruction], sampling_params)\n        #     candidate_text = outputs[0].outputs[0].text\n        # except Exception as e:\n        #     print(f"候補生成エラー: {e}")\n        #     candidate_text = f"エラーにより生成できませんでした: {e}"\n        \n        # 実際の実装では上記のVLLMコードを使用してください\n        candidate_text = f"数学問題の解答候補 {i+1}: {instruction[:100]}... に対する詳細な解答"\n        \n        # 品質スコアを計算（実際の実装では適切な評価指標を使用）\n        quality_score = max(0.1, 1.0 - (i * 0.2) + random.uniform(-0.05, 0.05))\n        \n        candidates.append({\n            "response": candidate_text,\n            "temperature": temp,\n            "quality_score": quality_score,\n            "candidate_id": i\n        })\n    \n    return candidates\n\ndef create_align_pairs(candidates):\n    """Alignデータ用のpreferred/rejectedペアを作成する"""\n    # 品質スコアでソート\n    sorted_candidates = sorted(candidates, key=lambda x: x["quality_score"], reverse=True)\n    \n    pairs = []\n    for i in range(len(sorted_candidates) - 1):\n        pairs.append({\n            "preferred": sorted_candidates[i],\n            "rejected": sorted_candidates[i + 1],\n            "preference_strength": sorted_candidates[i]["quality_score"] - sorted_candidates[i + 1]["quality_score"]\n        })\n    \n    return pairs\n\nif ENABLE_ALIGN_DATA and filtered_dataset:\n    print("🎯 Alignデータ生成（嗜好データ生成）を開始...")\n    \n    # Alignデータセット生成\n    align_dataset = []\n    \n    # 処理する問題数を制限（本番では全問題を処理）\n    sample_size = min(50, len(filtered_dataset))  # デモでは50問、本番では全問題\n    print(f"⚡ {sample_size}問題に対してAlignデータ候補を生成中...")\n    \n    for item in tqdm(filtered_dataset[:sample_size]):\n        instruction = item["instruction"]\n        \n        try:\n            # 複数候補を生成\n            candidates = generate_align_candidates(instruction)\n            \n            # Alignデータペアを作成\n            align_pairs = create_align_pairs(candidates)\n            \n            # Alignデータセットに追加\n            for pair in align_pairs:\n                align_item = {\n                    "instruction": instruction,\n                    "preferred_response": pair["preferred"]["response"],\n                    "rejected_response": pair["rejected"]["response"],\n                    "preference_strength": pair["preference_strength"],\n                    "preferred_quality": pair["preferred"]["quality_score"],\n                    "rejected_quality": pair["rejected"]["quality_score"],\n                    "preferred_temperature": pair["preferred"]["temperature"],\n                    "rejected_temperature": pair["rejected"]["temperature"],\n                    "domain": item.get("domain", "unknown"),\n                    "timestamp": int(time.time())\n                }\n                align_dataset.append(align_item)\n                \n        except Exception as e:\n            print(f"⚠️ 問題処理エラー: {e}")\n            continue\n    \n    print(f"✅ Alignデータセット生成完了: {len(align_dataset)}ペア")\n    \n    # Alignデータセットを保存\n    align_file = log_dir / f"Magpie_{MODEL_PATH.split(\"/\")[-1]}_Align_{len(align_dataset)}.json"\n    with open(align_file, "w", encoding="utf-8") as f:\n        json.dump(align_dataset, f, ensure_ascii=False, indent=2)\n    \n    print(f"💾 Alignデータセット保存: {align_file}")\n    \nelse:\n    if not ENABLE_ALIGN_DATA:\n        print("ℹ️ Alignデータ生成が無効になっています。ENABLE_ALIGN_DATA = True に設定してください。")\n    else:\n        print("⚠️ フィルタリング済みデータセットが見つかりません。Step 3を先に実行してください。")\n    align_dataset = None\n    align_file = None'),
    
    nbf.v4.new_markdown_cell('## 📊 Step 5: 最終レポートと統合'),
    
    nbf.v4.new_code_cell('print("📊 HLE数学データセット生成 - 最終レポート")\nprint("=" * 60)\n\n# 設定情報\nprint(f"🎯 データセット名: {DATASET_NAME}")\nprint(f"🤖 使用モデル: {MODEL_PATH}")\nprint(f"📅 生成日時: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}")\nprint(f"🎲 目標問題数: {TOTAL_PROBLEMS}")\n\n# 生成結果サマリー\nprint("\\n📈 生成結果サマリー:")\nif "filtered_dataset" in locals() and filtered_dataset:\n    print(f"  ✅ フィルタリング済み問題数: {len(filtered_dataset)}")\n    \n    if "align_dataset" in locals() and align_dataset:\n        print(f"  ✅ Alignデータペア数: {len(align_dataset)}")\n        print(f"  📊 平均選好強度: {np.mean([item[\"preference_strength\"] for item in align_dataset]):.3f}")\n    else:\n        print("  ⚠️ Alignデータは生成されませんでした")\nelse:\n    print("  ⚠️ データセットが生成されませんでした")\n\n# ファイル出力サマリー\nprint("\\n📁 出力ファイル:")\nif "log_dir" in locals():\n    output_files = list(log_dir.glob("*.json"))\n    for file in output_files:\n        print(f"  📄 {file.name}")\n\nprint("\\n🎉 HLE数学推論データセット生成プロセス完了！")\nprint("\\n💡 次のステップ:")\nprint("  1. 生成されたデータセットの品質を確認")\nprint("  2. 必要に応じてフィルタリング設定を調整")\nprint("  3. Alignデータを使用してモデルの微調整を実行")\nprint("  4. HLE対策用の評価指標でモデル性能を測定")')
]

nb.cells = cells

with open('demo_production.ipynb', 'w', encoding='utf-8') as f:
    nbf.write(nb, f)

print('✅ 本番用Jupyter Notebook作成完了')
