# æ±ç”¨æ•°å­¦ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# å¼•æ•°ãƒã‚§ãƒƒã‚¯ - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ã‚ˆã‚‹æ„å›³ã—ãªã„å®Ÿè¡Œã‚’é˜²ã
if [ -z "$1" ]; then
    echo "âŒ ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    echo "ğŸ“‹ ä½¿ç”¨æ–¹æ³•: $0 <model_path> [total_prompts] [control_tasks] [ins_topp] [ins_temp] [res_topp] [res_temp]"
    echo "ğŸ“ ä¾‹: $0 deepseek-ai/DeepSeek-R1-Distill-Qwen-32B 1000 math 1 1 1 0"
    echo "ğŸ”§ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¾‹:"
    echo "  - deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
    echo "  - deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
    echo "  - Qwen/Qwen2.5-Math-72B-Instruct"
    exit 1
fi

model_path="$1"  # ãƒ¢ãƒ‡ãƒ«åã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹ï¼ˆå¿…é ˆï¼‰
total_prompts=${2:-1000}  # ç”Ÿæˆã™ã‚‹å•é¡Œæ•°ã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹(å…¥åŠ›ã—ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1000)
control_tasks=${3:-"math"}  # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æŒ‡å®šã™ã‚‹å˜èªã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹ï¼ˆmathã€codeã€translationã€probabilityãªã©ï¼‰ï¼ˆ7/25å¼•æ•°è¿½åŠ ï¼‰
ins_topp=${4:-1}  # æŒ‡ç¤ºç”Ÿæˆã®top_pã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹(å…¥åŠ›ã—ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1)
ins_temp=${5:-1}  # æŒ‡ç¤ºç”Ÿæˆã®temperatureã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹(å…¥åŠ›ã—ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1)
res_topp=${6:-1}  # è§£ç­”ç”Ÿæˆã®top_pã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹(å…¥åŠ›ã—ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1)
res_temp=${7:-0}  # è§£ç­”ç”Ÿæˆã®temperatureã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹(å…¥åŠ›ã—ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯0)
res_rep=1  # è§£ç­”ç”Ÿæˆã®repetition_penaltyã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹(å…¥åŠ›ã—ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1)

device="0"  # GPUã‚’æŒ‡å®šã™ã‚‹

tensor_parallel=1  # ãƒ†ãƒ³ã‚½ãƒ«ä¸¦åˆ—åŒ–ã®ã‚µã‚¤ã‚ºã‚’æŒ‡å®šã™ã‚‹
gpu_memory_utilization=0.95  # GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã‚’æŒ‡å®šã™ã‚‹
# n=200
n=32  # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’èª¿æ•´
# batch_size=200
batch_size=32  # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’èª¿æ•´

# Get Current Time
timestamp=$(date +%s)

# Generate Pretty Name
# job_name="${model_path##*/}_topp${ins_topp}_temp${ins_temp}_${timestamp}"
job_name="${model_path##*/}_topp${ins_topp}_temp${ins_temp}_Number-Theory"

### Setup Logging
log_dir="data"
if [ ! -d "../${log_dir}" ]; then
    mkdir -p "../${log_dir}"
fi

job_path="../${log_dir}/${job_name}"

mkdir -p $job_path
exec > >(tee -a "$job_path/${job_name}.log") 2>&1
echo "[magpie.sh] Model Name: $model_path"
echo "[magpie.sh] Pretty name: $job_name"
echo "[magpie.sh] Total Prompts: $total_prompts"
echo "[magpie.sh] Instruction Generation Config: temp=$ins_temp, top_p=$ins_topp"
echo "[magpie.sh] Response Generation Config: temp=$res_temp, top_p=$res_topp, rep=$res_rep"
echo "[magpie.sh] System Config: device=$device, n=$n, batch_size=$batch_size, tensor_parallel=$tensor_parallel"
echo "[magpie.sh] Timestamp: $timestamp"
echo "[magpie.sh] Job Name: $job_name"

echo "[magpie.sh] Start Generating Instructions..."
CUDA_VISIBLE_DEVICES=$device python ../exp/gen_ins.py \
    --device $device \
    --model_path $model_path \
    --total_prompts $total_prompts \
    --top_p $ins_topp \
    --temperature $ins_temp \
    --tensor_parallel $tensor_parallel \
    --gpu_memory_utilization $gpu_memory_utilization \
    --control_tasks $control_tasks \
    --n $n \
    --job_name $job_name \
    --timestamp $timestamp

echo "[magpie.sh] Finish Generating Instructions!"

echo "[magpie.sh] Start Generating Responses..."
CUDA_VISIBLE_DEVICES=$device python ../exp/gen_res.py \
    --device $device \
    --model_path $model_path \
    --batch_size $batch_size \
    --top_p $res_topp \
    --temperature $res_temp \
    --repetition_penalty $res_rep \
    --tensor_parallel $tensor_parallel \
    --gpu_memory_utilization $gpu_memory_utilization \
    --input_file $job_path/Magpie_${model_path##*/}_${total_prompts}_${timestamp}_ins.json \
    --offline

echo "[magpie.sh] Finish Generating Responses!"
