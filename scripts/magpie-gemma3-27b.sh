#!/bin/bash

# Gemma 3 27B-it - Math Dataset Generation Script

# Require explicit model path argument
if [ -z "$1" ]; then
    echo "‚ùå „Ç®„É©„Éº: „É¢„Éá„É´„Éë„Çπ„ÅåÊåáÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì"
    echo "üìã ‰ΩøÁî®ÊñπÊ≥ï: $0 <model_path> [total_prompts] [ins_topp] [ins_temp] [res_topp] [res_temp]"
    echo "üí° ‰æã: $0 google/gemma-3-27b-it 1000"
    exit 1
fi
MODEL_PATH="$1"
TOTAL_PROMPTS="${2:-1000}"
INS_TOPP="${3:-1.0}"
INS_TEMP="${4:-1.2}"
RES_TOPP="${5:-1.0}"
RES_TEMP="${6:-0.1}"

echo "üßÆ Gemma 3 27B-it - Math Dataset Generation"
echo "========================================="
echo "Model: $MODEL_PATH"
echo "Total prompts: $TOTAL_PROMPTS"
echo "Instruction generation: top_p=$INS_TOPP, temp=$INS_TEMP"
echo "Response generation: top_p=$RES_TOPP, temp=$RES_TEMP"

cd "$(dirname "$0")"

TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
OUTPUT_DIR="../data/Gemma-3-27B-it_${TIMESTAMP}"
mkdir -p "$OUTPUT_DIR"

# Note: Gemma 3 27B requires specific attention to memory optimization
echo -e "\nüíé Using Gemma 3 27B for mathematical reasoning"

# Step 1: Generate math instructions
echo -e "\nüìù Generating math instructions..."
python ../exp/gen_ins.py \
    --model_path "$MODEL_PATH" \
    --save_path "$OUTPUT_DIR/math_ins.json" \
    --gpu_memory_utilization 0.9 \
    --total_prompts $TOTAL_PROMPTS \
    --tensor_parallel_size 2 \
    --top_p $INS_TOPP \
    --temperature $INS_TEMP \
    --control_tasks math \
    --max_tokens 512

# Step 2: Generate responses with Chain-of-Thought
echo -e "\nüß† Generating Chain-of-Thought responses..."
python ../exp/gen_res.py \
    --model_path "$MODEL_PATH" \
    --ins_data_path "$OUTPUT_DIR/math_ins.json" \
    --save_path "$OUTPUT_DIR/math_ins_res.json" \
    --gpu_memory_utilization 0.9 \
    --tensor_parallel_size 2 \
    --top_p $RES_TOPP \
    --temperature $RES_TEMP \
    --batch_size 8 \
    --max_tokens 2048

# Step 3: Generate multiple responses for alignment data
echo -e "\nüîÑ Generating multiple responses for preference learning..."
python ../exp/gen_po_multi_res.py \
    --model_path "$MODEL_PATH" \
    --ins_data_path "$OUTPUT_DIR/math_ins.json" \
    --save_path "$OUTPUT_DIR/math_ins_5res.json" \
    --gpu_memory_utilization 0.9 \
    --tensor_parallel_size 2 \
    --temperature 0.7 \
    --top_p 0.9 \
    --max_tokens 2048 \
    --num_responses 5

# Step 4: Evaluate response quality
echo -e "\n‚≠ê Evaluating response quality..."
python ../exp/gen_po_rewards.py \
    --model_name_or_path "RLHFlow/ArmoRM-Llama3-8B-v0.1" \
    --ins_data_path "$OUTPUT_DIR/math_ins_5res.json" \
    --save_path "$OUTPUT_DIR/math_ins_5res_armorm.json" \
    --gpu_memory_utilization 0.9 \
    --batch_size 16

echo -e "\n‚úÖ Generation complete!"
echo "Output files:"
echo "  - Instructions: $OUTPUT_DIR/math_ins.json"
echo "  - SFT data: $OUTPUT_DIR/math_ins_res.json"
echo "  - Preference data: $OUTPUT_DIR/math_ins_5res_armorm.json"