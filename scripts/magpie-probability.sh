#!/bin/bash

# Require explicit model path argument
if [ -z "$1" ]; then
    echo "âŒ ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    echo "ğŸ“‹ ä½¿ç”¨æ–¹æ³•: $0 <model_path> [total_prompts] [ins_topp] [ins_temp] [res_topp] [res_temp]"
    echo "ğŸ’¡ ä¾‹: $0 deepseek-ai/DeepSeek-R1 1000"
    exit 1
fi
model_path="$1"
total_prompts=${2:-1000}
ins_topp=${3:-1.0}
ins_temp=${4:-1.2}
res_topp=${5:-1.0}
res_temp=${6:-0.1}

res_rep=1
device="0"
tensor_parallel=1  # RTX A2000ç”¨ã«èª¿æ•´
gpu_memory_utilization=0.85
n=32  # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’èª¿æ•´
batch_size=32

timestamp=$(date +%s)

job_name="DeepSeek-R1-Probability_${total_prompts}_${timestamp}"

log_dir="data"
if [ ! -d "../${log_dir}" ]; then
    mkdir -p "../${log_dir}"
fi

job_path="../${log_dir}/${job_name}"

mkdir -p $job_path
exec > >(tee -a "$job_path/${job_name}.log") 2>&1

echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] ãƒ¢ãƒ‡ãƒ«å: $model_path"
echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] ã‚¸ãƒ§ãƒ–å: $job_name"
echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] ç·å•é¡Œæ•°: $total_prompts"
echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] å•é¡Œç”Ÿæˆè¨­å®š: temp=$ins_temp, top_p=$ins_topp"
echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] è§£ç­”ç”Ÿæˆè¨­å®š: temp=$res_temp, top_p=$res_topp, rep=$res_rep"
echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] ã‚·ã‚¹ãƒ†ãƒ è¨­å®š: device=$device, n=$n, batch_size=$batch_size, tensor_parallel=$tensor_parallel"
echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: $timestamp"
echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] GPUä½¿ç”¨ç‡: $gpu_memory_utilization"

echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] ç¢ºç‡å•é¡Œç”Ÿæˆã‚’é–‹å§‹..."
CUDA_VISIBLE_DEVICES=$device python ../exp/gen_ins.py \
    --device $device \
    --model_path $model_path \
    --total_prompts $total_prompts \
    --top_p $ins_topp \
    --temperature $ins_temp \
    --tensor_parallel_size $tensor_parallel \
    --gpu_memory_utilization $gpu_memory_utilization \
    --control_tasks probability \
    --n $n \
    --job_name $job_name \
    --timestamp $timestamp \
    --max_tokens 3072 \
    --max_model_len 8192

echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] ç¢ºç‡å•é¡Œç”Ÿæˆå®Œäº†ï¼"

echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] ç¢ºç‡è§£ç­”ç”Ÿæˆã‚’é–‹å§‹..."
CUDA_VISIBLE_DEVICES=$device python ../exp/gen_res.py \
    --device $device \
    --model_path $model_path \
    --batch_size $batch_size \
    --top_p $res_topp \
    --temperature $res_temp \
    --repetition_penalty $res_rep \
    --tensor_parallel_size $tensor_parallel \
    --gpu_memory_utilization $gpu_memory_utilization \
    --input_file $job_path/Magpie_${model_path##*/}_${total_prompts}_${timestamp}_ins.json \
    --use_tokenizer_template \
    --offline \
    --max_tokens 4096

echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] ç¢ºç‡è§£ç­”ç”Ÿæˆå®Œäº†ï¼"
echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] ç¢ºç‡ç†è«–ç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚"
echo "[ç¢ºç‡åˆ†é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ] å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: $job_path/"
